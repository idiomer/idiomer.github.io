<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>onnx和模型量化.md</title>
      <link href="/p/onnx%E5%92%8C%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.md/"/>
      <url>/p/onnx%E5%92%8C%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96.md/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install onnx onnxruntime -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com</span><br><span class="line"><span class="comment"># pip install onnxruntime-openvino -i http://mirrors.cloud.aliyuncs.com/pypi/simple/ --trusted-host=mirrors.cloud.aliyuncs.com</span></span><br></pre></td></tr></table></figure><h2 id="PyTorch导出onnx模型"><a href="#PyTorch导出onnx模型" class="headerlink" title="PyTorch导出onnx模型"></a>PyTorch导出onnx模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参考：https://pytorch.ac.cn/tutorials/advanced/super_resolution_with_onnxruntime.html</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一、定义模型输入数据和计算输出结果</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">x = torch.randn(batch_size, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">torch_out = torch_model(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二、torch原生支持导出onnx模型</span></span><br><span class="line">torch.onnx.export(torch_model,               <span class="comment"># model being run</span></span><br><span class="line">                  x,                         <span class="comment"># model input (or a tuple for multiple inputs)</span></span><br><span class="line">                  <span class="string">&quot;vit.onnx&quot;</span>,                <span class="comment"># where to save the model (can be a file or file-like object)</span></span><br><span class="line">                  export_params=<span class="literal">True</span>,        <span class="comment"># store the trained parameter weights inside the model file</span></span><br><span class="line">                  opset_version=<span class="number">16</span>,          <span class="comment"># the ONNX version to export the model to ≥14</span></span><br><span class="line">                  do_constant_folding=<span class="literal">True</span>,  <span class="comment"># whether to execute constant folding for optimization</span></span><br><span class="line">                  input_names = [<span class="string">&#x27;input&#x27;</span>],   <span class="comment"># the model&#x27;s input names</span></span><br><span class="line">                  output_names = [<span class="string">&#x27;output&#x27;</span>], <span class="comment"># the model&#x27;s output names</span></span><br><span class="line">                  dynamic_axes=&#123;<span class="string">&#x27;input&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;,    <span class="comment"># variable length axes</span></span><br><span class="line">                                <span class="string">&#x27;output&#x27;</span> : &#123;<span class="number">0</span> : <span class="string">&#x27;batch_size&#x27;</span>&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三、检查导出的onnx模型</span></span><br><span class="line">onnx_model = onnx.load(<span class="string">&quot;vit.onnx&quot;</span>)</span><br><span class="line">onnx.checker.check_model(onnx_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 四、验证onnx模型输出结果和torch模型输出结果对比</span></span><br><span class="line"><span class="comment">## 4.1 配置onnxruntime运行时参数，并加载刚导出的模型</span></span><br><span class="line">num_logical_cpus = <span class="number">4</span>  <span class="comment"># os.cpu_count()</span></span><br><span class="line">sess_options = onnxruntime.SessionOptions()</span><br><span class="line">sess_options.intra_op_num_threads = num_logical_cpus</span><br><span class="line"><span class="comment">#sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL   # 启用图优化</span></span><br><span class="line">ort_session = onnxruntime.InferenceSession(<span class="string">&quot;vit_quant.onnx&quot;</span>, sess_options, providers=[<span class="string">&quot;CPUExecutionProvider&quot;</span>])</span><br><span class="line"><span class="comment">#ort_session = onnxruntime.InferenceSession(&quot;vit_quant.onnx&quot;, sess_options, providers=[&quot;OpenVINOExecutionProvider&quot;], provider_options=[&#123;&quot;cache_dir&quot;: &quot;./cache&quot;,&quot;device_type&quot;: &quot;CPU&quot;, &quot;num_of_threads&quot;: num_logical_cpus, &quot;precision&quot;: &quot;FP32&quot;&#125;]))  # 采用OpenVINO推理，针对部分Intel CPU</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 4.2 onnxruntime推理：计算结果，并和torch的输出结果对比</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_numpy</span>(<span class="params">tensor</span>):</span><br><span class="line">    <span class="keyword">return</span> tensor.detach().cpu().numpy() <span class="keyword">if</span> tensor.requires_grad <span class="keyword">else</span> tensor.cpu().numpy()</span><br><span class="line"></span><br><span class="line">ort_inputs = &#123;ort_session.get_inputs()[<span class="number">0</span>].name: to_numpy(x)&#125;</span><br><span class="line">ort_outs = ort_session.run(<span class="literal">None</span>, ort_inputs); <span class="built_in">print</span>(torch_out.detach().numpy(), <span class="string">&quot;\n&quot;</span>, ort_outs[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">np.testing.assert_allclose(to_numpy(torch_out), ort_outs[<span class="number">0</span>], rtol=<span class="number">1e-03</span>, atol=<span class="number">1e-05</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Exported model has been tested with ONNXRuntime, and the result looks good!&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="ONNX动态量化模型"><a href="#ONNX动态量化模型" class="headerlink" title="ONNX动态量化模型"></a>ONNX动态量化模型</h2><h3 id="INT8动态量化"><a href="#INT8动态量化" class="headerlink" title="INT8动态量化"></a>INT8动态量化</h3><ol><li>参数量化<ul><li>对于每层的模型参数$W$，采用Min-Max归一化，将参数归一化到[0,255]或[-128,127]</li><li>保存量化后的参数$W_q$，以及每层Min-Max归一化的scale和zero_point</li></ul></li><li>输入&#x2F;激活值(动态)量化<ul><li>对于每层的输入向量$X$，同样采用Min-Max归一化，将参数归一化到[0,255]或[-128,127]</li><li>由于每次的输入和激活值都是不同的，因此，需要实时动态计算量化后的$X_q$，以及scale和zero_point</li></ul></li><li>计算 &amp; 反量化<ul><li>**计算(以linear层为例)*<em>：$ X@W &#x3D; (X_q * scale_x) @ (W_q * scale_w) &#x3D; (scale_x</em>scale_w) * (X_q @ W_q) $<ul><li>其中scale都是标量，X和W都是向量，@是矩阵乘法。</li><li>通过公式，我们可以将浮点数的矩阵乘法，转换为INT8的矩阵乘法，从而降低计算量，加速推理</li></ul></li><li><strong>反量化</strong>：将上述的结果反量化回浮点数FP32，继续执行sigmoid,tanh等激活函数；之后做为下一层的输入，执行”输入&#x2F;激活值量化”</li></ul></li></ol><p><img src="https://pic1.zhimg.com/v2-45fd7d5ede2b518c31e40c24a5085f32_r.jpg" alt="对称量化"><br><img src="https://pic2.zhimg.com/v2-196d043ae9197b591b4e11fbb42e7025_r.jpg" alt="非对称量化"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> onnxruntime.quantization <span class="keyword">import</span> quantize_dynamic, QuantType</span><br><span class="line"></span><br><span class="line">all_nodes = [n.name <span class="keyword">for</span> n <span class="keyword">in</span> model.graph.node <span class="keyword">if</span> n.op_type <span class="keyword">in</span> (<span class="string">&#x27;Conv&#x27;</span>, <span class="string">&#x27;MatMul&#x27;</span>, <span class="string">&#x27;Gemm&#x27;</span>)]</span><br><span class="line">nodes_to_quantize = all_nodes[:]  <span class="comment"># all_nodes[:len(all_nodes)//4*3]</span></span><br><span class="line"></span><br><span class="line">quantize_dynamic(</span><br><span class="line">    <span class="string">&quot;vit.onnx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;vit_quant.onnx&quot;</span>,</span><br><span class="line">    <span class="comment"># op_types_to_quantize=[&#x27;Conv&#x27;, &#x27;MatMul&#x27;, &#x27;Add&#x27;, &#x27;Gemm&#x27;],</span></span><br><span class="line">    nodes_to_quantize=nodes_to_quantize,</span><br><span class="line">    weight_type=QuantType.QUInt8,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/29140505773">大模型(LLM)量化(Quantization)原理学习 – 知乎</a></li><li><a href="https://www.bilibili.com/video/BV1pZ421J7ga">模型量化二：训练后动态量化 PTQ PTDQ，pytorch里进行模型训练后动态量化</a></li><li><a href="https://rapidai.github.io/RapidOCRDocs/blog/2022/09/23/onnxruntime-cpu%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/">onnxruntime-cpu推理优化</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Head Attention理解和PyTorch实现</title>
      <link href="/p/Multi-Head%20Attention%E7%90%86%E8%A7%A3%E5%92%8CPyTorch%E5%AE%9E%E7%8E%B0/"/>
      <url>/p/Multi-Head%20Attention%E7%90%86%E8%A7%A3%E5%92%8CPyTorch%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="一、基础版"><a href="#一、基础版" class="headerlink" title="一、基础版"></a>一、基础版</h1><h2 id="SelfAttention"><a href="#SelfAttention" class="headerlink" title="SelfAttention"></a>SelfAttention</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(SelfAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义三个线性层分别生成Q, K, V</span></span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Linear(embed_size, embed_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x形状: (batch_size, seq_length, embed_size)</span></span><br><span class="line">        batch_size, seq_len, _ = x.size()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成Q, K, V [均为(batch_size, seq_len, embed_size)]</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query(x)</span><br><span class="line">        K = <span class="variable language_">self</span>.key(x)</span><br><span class="line">        V = <span class="variable language_">self</span>.value(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算注意力分数</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, seq_len)</span></span><br><span class="line">        scores = torch.bmm(Q, K.transpose(<span class="number">1</span>, <span class="number">2</span>)) / (<span class="variable language_">self</span>.embed_size ** <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用softmax得到注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用注意力权重到V</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, embed_size)</span></span><br><span class="line">        output = torch.bmm(attention_weights, V)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 超参数</span></span><br><span class="line">    embed_size = <span class="number">4</span>  <span class="comment"># 嵌入维度</span></span><br><span class="line">    seq_len = <span class="number">3</span>     <span class="comment"># 序列长度</span></span><br><span class="line">    batch_size = <span class="number">1</span>   <span class="comment"># 批大小</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建自注意力模块</span></span><br><span class="line">    sa = SelfAttention(embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建随机输入 (模拟一个batch的输入)</span></span><br><span class="line">    x = torch.rand(batch_size, seq_len, embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    output, attention_weights = sa(x)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入形状:&quot;</span>, x.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输出形状:&quot;</span>, output.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;注意力权重形状:&quot;</span>, attention_weights.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n注意力权重矩阵:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attention_weights.squeeze().detach())</span><br></pre></td></tr></table></figure><h2 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size=<span class="number">512</span>, num_heads=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = embed_size // num_heads</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 确保embed_size可以被num_heads整除</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.head_dim * num_heads == embed_size, <span class="string">&quot;Embed size needs to be divisible by num_heads&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义四个线性层（Q, K, V和最终输出）</span></span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(embed_size, embed_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batch_size, seq_len, _ = x.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成Q, K, V [shape: (batch_size, seq_len, embed_size)]</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query(x)</span><br><span class="line">        K = <span class="variable language_">self</span>.key(x)</span><br><span class="line">        V = <span class="variable language_">self</span>.value(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割多头：将embed_size维度拆分为num_heads x head_dim</span></span><br><span class="line">        <span class="comment"># 新形状： (batch_size, seq_len, num_heads, head_dim)</span></span><br><span class="line">        Q = Q.view(batch_size, seq_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        K = K.view(batch_size, seq_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        V = V.view(batch_size, seq_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调整维度顺序用于矩阵乘法</span></span><br><span class="line">        <span class="comment"># 新形状： (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">        Q = Q.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        K = K.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        V = V.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算缩放点积注意力分数</span></span><br><span class="line">        scores = torch.matmul(Q, K.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)) / (<span class="variable language_">self</span>.head_dim ** <span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># scores形状: (batch_size, num_heads, seq_len, seq_len)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用softmax得到注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用注意力权重到V</span></span><br><span class="line">        weighted = torch.matmul(attention_weights, V)</span><br><span class="line">        <span class="comment"># weighted形状: (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 合并多头结果</span></span><br><span class="line">        <span class="comment"># 1. 调整维度顺序 (batch_size, seq_len, num_heads, head_dim)</span></span><br><span class="line">        weighted = weighted.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 2. 合并最后两个维度 (batch_size, seq_len, embed_size)</span></span><br><span class="line">        weighted = weighted.contiguous().view(batch_size, seq_len, <span class="variable language_">self</span>.embed_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 通过最终线性层</span></span><br><span class="line">        output = <span class="variable language_">self</span>.fc_out(weighted)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 参数设置</span></span><br><span class="line">    embed_size = <span class="number">8</span>  <span class="comment"># 总嵌入维度</span></span><br><span class="line">    num_heads = <span class="number">2</span>   <span class="comment"># 注意力头数量</span></span><br><span class="line">    seq_len = <span class="number">4</span>     <span class="comment"># 序列长度</span></span><br><span class="line">    batch_size = <span class="number">1</span>   <span class="comment"># 批大小</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建多头注意力模块</span></span><br><span class="line">    mha = MultiHeadAttention(embed_size, num_heads)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建随机输入 (模拟一个batch的输入)</span></span><br><span class="line">    x = torch.rand(batch_size, seq_len, embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    output, attention_weights = mha(x)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入形状:&quot;</span>, x.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输出形状:&quot;</span>, output.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;注意力权重形状:&quot;</span>, attention_weights.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n第一个头的注意力矩阵:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attention_weights[<span class="number">0</span>, <span class="number">0</span>].detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br></pre></td></tr></table></figure><h1 id="二、Mask版"><a href="#二、Mask版" class="headerlink" title="二、Mask版"></a>二、Mask版</h1><h2 id="SelfAttention-With-Mask"><a href="#SelfAttention-With-Mask" class="headerlink" title="SelfAttention With Mask"></a>SelfAttention With Mask</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(SelfAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义三个线性层分别生成Q, K, V</span></span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Linear(embed_size, embed_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        x: 输入张量 (batch_size, seq_len, embed_size)</span></span><br><span class="line"><span class="string">        mask: 掩码张量，支持两种类型:</span></span><br><span class="line"><span class="string">            - Padding mask (batch_size, 1, 1, seq_len)</span></span><br><span class="line"><span class="string">            - Sequence mask (batch_size, 1, seq_len, seq_len)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># x形状: (batch_size, seq_length, embed_size)</span></span><br><span class="line">        batch_size, seq_len, _ = x.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成Q, K, V [均为(batch_size, seq_len, embed_size)]</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query(x)</span><br><span class="line">        K = <span class="variable language_">self</span>.key(x)</span><br><span class="line">        V = <span class="variable language_">self</span>.value(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算注意力分数</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, seq_len)</span></span><br><span class="line">        scores = torch.bmm(Q, K.transpose(<span class="number">1</span>, <span class="number">2</span>)) / (<span class="variable language_">self</span>.embed_size ** <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用掩码（如果存在）</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            掩码逻辑:</span></span><br><span class="line"><span class="string">            - 对于需要屏蔽的位置，设置其分数为极小的值(-1e9)</span></span><br><span class="line"><span class="string">            - 注意mask的形状需要与scores兼容</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            <span class="comment"># 调整mask形状 (如果是2D则扩展为3D)</span></span><br><span class="line">            <span class="keyword">if</span> mask.dim() == <span class="number">2</span>:</span><br><span class="line">                mask = mask.unsqueeze(<span class="number">1</span>)  <span class="comment"># (batch_size, 1, seq_len)</span></span><br><span class="line">            <span class="keyword">elif</span> mask.dim() == <span class="number">3</span>:</span><br><span class="line">                mask = mask.unsqueeze(<span class="number">1</span>)  <span class="comment"># (batch_size, 1, seq_len, seq_len)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 应用mask到注意力分数</span></span><br><span class="line">            scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用softmax得到注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用注意力权重到V</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, embed_size)</span></span><br><span class="line">        output = torch.bmm(attention_weights, V)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 超参数</span></span><br><span class="line">    embed_size = <span class="number">4</span>  <span class="comment"># 嵌入维度</span></span><br><span class="line">    seq_len = <span class="number">3</span>     <span class="comment"># 序列长度</span></span><br><span class="line">    batch_size = <span class="number">1</span>   <span class="comment"># 批大小</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建自注意力模块</span></span><br><span class="line">    sa = SelfAttention(embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试1: 基础用法（无mask）</span></span><br><span class="line">    x = torch.rand(batch_size, seq_len, embed_size)</span><br><span class="line">    output, attn = sa(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;无mask的注意力权重:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn.squeeze().detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试2: 应用padding mask</span></span><br><span class="line">    <span class="comment"># 假设第二个位置是padding</span></span><br><span class="line">    padding_mask = torch.tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]], dtype=torch.float32)  <span class="comment"># (batch_size, seq_len)</span></span><br><span class="line">    _, attn_pad = sa(x, mask=padding_mask)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n带padding mask的注意力权重:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn_pad.squeeze().detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试3: 应用sequence mask（解码器用）</span></span><br><span class="line">    sequence_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=<span class="number">1</span>).<span class="built_in">bool</span>()</span><br><span class="line">    sequence_mask = sequence_mask.unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, seq_len, seq_len)</span></span><br><span class="line">    _, attn_seq = sa(x, mask=sequence_mask)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n带sequence mask的注意力权重:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn_seq.squeeze().detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br></pre></td></tr></table></figure><h2 id="Multi-Head-Attention-With-Mask"><a href="#Multi-Head-Attention-With-Mask" class="headerlink" title="Multi-Head Attention With Mask"></a>Multi-Head Attention With Mask</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size=<span class="number">512</span>, num_heads=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = embed_size // num_heads</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.head_dim * num_heads == embed_size, <span class="string">&quot;Embed size must be divisible by num_heads&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义四个线性层</span></span><br><span class="line">        <span class="variable language_">self</span>.query = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.key = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.value = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(embed_size, embed_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        x: 输入张量 (batch_size, seq_len, embed_size)</span></span><br><span class="line"><span class="string">        mask: 支持两种掩码类型:</span></span><br><span class="line"><span class="string">            - Padding mask: (batch_size, 1, 1, seq_len)</span></span><br><span class="line"><span class="string">            - Sequence mask: (batch_size, 1, seq_len, seq_len)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size, seq_len, _ = x.shape</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成Q, K, V</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query(x)</span><br><span class="line">        K = <span class="variable language_">self</span>.key(x)</span><br><span class="line">        V = <span class="variable language_">self</span>.value(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 分割多头 [batch_size, seq_len, num_heads, head_dim]</span></span><br><span class="line">        Q = Q.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        K = K.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        V = V.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算注意力分数 [batch_size, num_heads, seq_len, seq_len]</span></span><br><span class="line">        scores = torch.matmul(Q, K.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)) / (<span class="variable language_">self</span>.head_dim ** <span class="number">0.5</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用掩码</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            掩码处理规则:</span></span><br><span class="line"><span class="string">            1. 自动适配不同维度的mask输入</span></span><br><span class="line"><span class="string">            2. 将mask转换为布尔类型</span></span><br><span class="line"><span class="string">            3. 在注意力分数上应用mask</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            <span class="comment"># 调整mask维度</span></span><br><span class="line">            <span class="keyword">if</span> mask.dim() == <span class="number">2</span>:  <span class="comment"># (batch_size, seq_len) → Padding mask</span></span><br><span class="line">                mask = mask.unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># [batch_size, 1, 1, seq_len]</span></span><br><span class="line">            <span class="keyword">elif</span> mask.dim() == <span class="number">3</span>:  <span class="comment"># (batch_size, seq_len, seq_len) → Sequence mask</span></span><br><span class="line">                mask = mask.unsqueeze(<span class="number">1</span>)  <span class="comment"># [batch_size, 1, seq_len, seq_len]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 确保mask数据类型为布尔型</span></span><br><span class="line">            mask = mask.to(torch.<span class="built_in">bool</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 应用mask（自动广播到所有注意力头）</span></span><br><span class="line">            scores = scores.masked_fill(mask, -<span class="number">1e9</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算上下文向量</span></span><br><span class="line">        context = torch.matmul(attention_weights, V)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 合并多头 [batch_size, seq_len, embed_size]</span></span><br><span class="line">        context = context.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">        context = context.view(batch_size, seq_len, <span class="variable language_">self</span>.embed_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 最终线性变换</span></span><br><span class="line">        output = <span class="variable language_">self</span>.fc_out(context)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 参数设置</span></span><br><span class="line">    embed_size = <span class="number">8</span></span><br><span class="line">    num_heads = <span class="number">2</span></span><br><span class="line">    seq_len = <span class="number">4</span></span><br><span class="line">    batch_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化模块</span></span><br><span class="line">    mha = MultiHeadAttention(embed_size, num_heads)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试输入</span></span><br><span class="line">    x = torch.rand(batch_size, seq_len, embed_size)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===== 测试1: 无掩码 =====&quot;</span>)</span><br><span class="line">    out, attn = mha(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;注意力权重形状: <span class="subst">&#123;attn.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第一个头的注意力矩阵:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn[<span class="number">0</span>, <span class="number">0</span>].detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n===== 测试2: 应用Padding掩码 =====&quot;</span>)</span><br><span class="line">    padding_mask = torch.tensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=torch.<span class="built_in">bool</span>)  <span class="comment"># 最后两个位置是padding</span></span><br><span class="line">    _, attn_pad = mha(x, mask=padding_mask)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;带padding mask的注意力矩阵:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn_pad[<span class="number">0</span>, <span class="number">0</span>].detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n===== 测试3: 应用Sequence掩码 =====&quot;</span>)</span><br><span class="line">    seq_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=<span class="number">1</span>).<span class="built_in">bool</span>()</span><br><span class="line">    seq_mask = seq_mask.unsqueeze(<span class="number">0</span>)  <span class="comment"># 添加batch维度</span></span><br><span class="line">    _, attn_seq = mha(x, mask=seq_mask)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;带sequence mask的注意力矩阵:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(attn_seq[<span class="number">0</span>, <span class="number">0</span>].detach().numpy().<span class="built_in">round</span>(<span class="number">3</span>))</span><br></pre></td></tr></table></figure><h1 id="三、统一实现"><a href="#三、统一实现" class="headerlink" title="三、统一实现"></a>三、统一实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size=<span class="number">512</span>, num_heads=<span class="number">8</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = embed_size // num_heads</span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.head_dim * num_heads == embed_size, <span class="string">&quot;Embed size must be divisible by num_heads&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义QKV</span></span><br><span class="line">        <span class="variable language_">self</span>.Q = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.K = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.V = nn.Linear(embed_size, embed_size)</span><br><span class="line">        <span class="variable language_">self</span>.scale = torch.sqrt(<span class="variable language_">self</span>.head_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义softmax</span></span><br><span class="line">        <span class="variable language_">self</span>.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        X: [batch_size, seq_len, emb_dim]</span></span><br><span class="line"><span class="string">        mask:</span></span><br><span class="line"><span class="string">            - [batch_size, seq_len] for padding mask</span></span><br><span class="line"><span class="string">            - [batch_size, seq_len, seq_len] for causual mask</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 单头注意力机制</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.num_heads &lt;= <span class="number">1</span>:</span><br><span class="line">            query = <span class="variable language_">self</span>.Q(X)</span><br><span class="line">            key = <span class="variable language_">self</span>.K(X)</span><br><span class="line">            value = <span class="variable language_">self</span>.V(X)   <span class="comment"># [batch_size, seq_len, emb_dim]</span></span><br><span class="line"></span><br><span class="line">            scores = torch.bmm(query, key.transpose(<span class="number">1</span>, <span class="number">2</span>)) / <span class="variable language_">self</span>.scale  <span class="comment"># [batch_size, seq_len, seq_len]</span></span><br><span class="line">            <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">if</span> mask.dim() == <span class="number">2</span>:</span><br><span class="line">                    mask = mask.unsqueeze(dim=<span class="number">1</span>)  <span class="comment"># [batch_size, 1, seq_len]</span></span><br><span class="line">                <span class="keyword">elif</span> mask.dim() == <span class="number">3</span>:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">f&quot;The dim of mask must be 2 or 3!&quot;</span>)</span><br><span class="line">                scores = scores.mask_fill(mask==<span class="number">0</span>, -<span class="number">1e9</span>)  <span class="comment"># 利用广播</span></span><br><span class="line">            attention_weights = <span class="variable language_">self</span>.softmax(scores)       <span class="comment"># [batch_size, seq_len, seq_len]</span></span><br><span class="line">            output = torch.bmm(attention_weights, value)   <span class="comment"># [batch_size, seq_len, emb_dim]</span></span><br><span class="line">            <span class="keyword">return</span> output</span><br><span class="line">        <span class="comment"># 多头注意力机制</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            batch_size, seq_len, _emb_dim  = X.size()</span><br><span class="line">            query = <span class="variable language_">self</span>.Q(X).view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">            key = <span class="variable language_">self</span>.K(X).view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">            value = <span class="variable language_">self</span>.V(X).view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)   <span class="comment"># [batch_size, seq_len, heads, head_dim]</span></span><br><span class="line"></span><br><span class="line">            scores = torch.matmul(query.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>), key.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)) / <span class="variable language_">self</span>.scale  <span class="comment"># [batch_size, heads, seq_len, seq_len]</span></span><br><span class="line">            <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">if</span> mask.dim() == <span class="number">2</span>:</span><br><span class="line">                    mask = mask.unsqueeze(dim=<span class="number">1</span>).unsqueeze(dim=<span class="number">1</span>)  <span class="comment"># [batch_size, 1, 1, seq_len]</span></span><br><span class="line">                <span class="keyword">elif</span> mask.dim() == <span class="number">3</span>:</span><br><span class="line">                    mask = mask.unsqueeze(dim=<span class="number">1</span>)             <span class="comment"># [batch_size, 1, seq_len, seq_len]</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">f&quot;The dim of mask must be 2 or 3!&quot;</span>)</span><br><span class="line">                scores = scores.mask_fill(mask==<span class="number">0</span>, -<span class="number">1e9</span>)  <span class="comment"># 利用广播</span></span><br><span class="line">            attention_weights = <span class="variable language_">self</span>.softmax(scores)   <span class="comment"># [batch_size, heads, seq_len, seq_len]</span></span><br><span class="line">            output = torch.matmul(attention_weights, value.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>))   <span class="comment"># [batch_size, heads, seq_len, head_dim]</span></span><br><span class="line">            output = output.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).contiguous().view(batch_size, seq_len, <span class="variable language_">self</span>.embed_size)</span><br><span class="line">            <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li><li><a href="https://github.com/karpathy/nanoGPT">karpathy&#x2F;nanoGPT – github</a></li><li><a href="https://github.com/jingyaogong/minimind">jingyaogong&#x2F;minimind – github</a></li><li><a href="https://zhuanlan.zhihu.com/p/19630799254">大模型数据集全面整理: 444个数据集下载地址，出自LLM训练数据集调研经典论文《Datasets for Large Language Models: A Comprehensive Survey》</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Self-Attention </tag>
            
            <tag> Multi-Head Attention </tag>
            
            <tag> Transformer </tag>
            
            <tag> BERT </tag>
            
            <tag> GPT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的归一化层</title>
      <link href="/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82/"/>
      <url>/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="一、常用-Norm-介绍"><a href="#一、常用-Norm-介绍" class="headerlink" title="一、常用 Norm 介绍"></a>一、常用 Norm 介绍</h1><h2 id="LayerNorm"><a href="#LayerNorm" class="headerlink" title="LayerNorm"></a><strong>LayerNorm</strong></h2><p>LayerNorm 是一种神经网络中的归一化技术，用于稳定训练过程（缓解梯度消失&#x2F;爆炸），加速收敛。它的核心思想是 <strong>对单个样本的某一层所有神经元的输出进行归一化</strong></p><h3 id="①-计算方式"><a href="#①-计算方式" class="headerlink" title="① 计算方式"></a>① 计算方式</h3><p>在 Transformer 或 GPT 这类模型中，输入张量的形状通常是 [batch_size, seq_len, hidden_dim]，而 LayerNorm 会沿着 hidden_dim 维度进行归一化。</p><p>对于形状为 [batch_size, seq_len, hidden_dim] 的输入，LayerNorm 的归一化是 对最后一个维度（hidden_dim）独立进行的，即：</p><ul><li>每个 token 的特征向量（长度为 hidden_dim）单独归一化。</li><li>均值和方差的计算：对每个样本的每个时间步（即 [hidden_dim] 维度）计算均值和方差。</li></ul><p>具体计算步骤如下：</p><p>给定输入张量 x（形状 [batch_size, seq_len, hidden_dim]）：</p><ol><li><strong>计算均值和方差</strong>：<ul><li>对每个样本的每个时间步（即 hidden_dim 维度）计算：<br> [<br>  \mu &#x3D; \frac{1}{d} \sum_{i&#x3D;1}^d x_i, \quad \sigma^2 &#x3D; \frac{1}{d} \sum_{i&#x3D;1}^d (x_i - \mu)^2<br> ]<br> （其中 ( d &#x3D; \text{hidden_dim} )）</li></ul></li><li><strong>归一化</strong>：<br> [<br> \hat{x} &#x3D; \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}<br> ]</li><li><strong>缩放和平移</strong>：<br> [<br> y &#x3D; \gamma \hat{x} + \beta<br> ]<br> （<code>gamma</code> 和 <code>beta</code> 是可学习的参数，形状为 <code>[hidden_dim]</code>）</li></ol><h3 id="②-具体例子"><a href="#②-具体例子" class="headerlink" title="② 具体例子"></a>② 具体例子</h3><p>假设：</p><ul><li><code>batch_size = 2</code></li><li><code>seq_len = 3</code></li><li><code>hidden_dim = 4</code></li><li>输入数据：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([</span><br><span class="line">    <span class="comment"># 样本 1 (3 tokens, 每个 token 4 维)</span></span><br><span class="line">    [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>],</span><br><span class="line">     [<span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>],</span><br><span class="line">     [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]],</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 样本 2 (3 tokens, 每个 token 4 维)</span></span><br><span class="line">    [[-<span class="number">1.0</span>, -<span class="number">2.0</span>, -<span class="number">3.0</span>, -<span class="number">4.0</span>],</span><br><span class="line">     [-<span class="number">2.0</span>, -<span class="number">3.0</span>, -<span class="number">4.0</span>, -<span class="number">5.0</span>],</span><br><span class="line">     [-<span class="number">3.0</span>, -<span class="number">4.0</span>, -<span class="number">5.0</span>, -<span class="number">6.0</span>]]</span><br><span class="line">])  <span class="comment"># 形状 [2, 3, 4]</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="I-手动计算-LayerNorm"><a href="#I-手动计算-LayerNorm" class="headerlink" title="I. 手动计算 LayerNorm"></a>I. 手动计算 LayerNorm</h4><p>以第一个样本的第一个 token <code>[1.0, 2.0, 3.0, 4.0]</code> 为例：</p><ol><li><strong>计算均值</strong>：<br>[<br>\mu &#x3D; \frac{1 + 2 + 3 + 4}{4} &#x3D; 2.5<br>]</li><li><strong>计算方差</strong>：<br>[<br>\sigma^2 &#x3D; \frac{(1-2.5)^2 + (2-2.5)^2 + (3-2.5)^2 + (4-2.5)^2}{4} &#x3D; 1.25<br>]</li><li><strong>归一化</strong>：<br>[<br>\hat{x} &#x3D; \frac{[1.0, 2.0, 3.0, 4.0] - 2.5}{\sqrt{1.25 + 1e-5}} \approx [-1.3416, -0.4472, 0.4472, 1.3416]<br>]</li><li><strong>缩放和平移</strong>（假设 <code>gamma=1</code>, <code>beta=0</code>）：<br>[<br>y &#x3D; 1.0 \times \hat{x} + 0.0 &#x3D; \hat{x}<br>]</li></ol><h4 id="II-PyTorch-验证"><a href="#II-PyTorch-验证" class="headerlink" title="II. PyTorch 验证"></a>II. PyTorch 验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">layernorm = torch.nn.LayerNorm(<span class="number">4</span>)  <span class="comment"># 对 hidden_dim 归一化</span></span><br><span class="line">output = layernorm(x)</span><br><span class="line"><span class="built_in">print</span>(output[<span class="number">0</span>, <span class="number">0</span>])  <span class="comment"># 第一个样本的第一个 token</span></span><br></pre></td></tr></table></figure><p><strong>输出</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-1.3416, -0.4472,  0.4472,  1.3416], grad_fn=&lt;SelectBackward&gt;)</span><br></pre></td></tr></table></figure><p>与手动计算一致！</p><h3 id="③-PyTorch实现"><a href="#③-PyTorch实现" class="headerlink" title="③ PyTorch实现"></a>③ PyTorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gamma = nn.Parameter(torch.ones(hidden_dim))  <span class="comment"># 缩放参数</span></span><br><span class="line">        <span class="variable language_">self</span>.beta = nn.Parameter(torch.zeros(hidden_dim))   <span class="comment"># 平移参数</span></span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)                     <span class="comment"># 计算均值</span></span><br><span class="line">        var = x.var(-<span class="number">1</span>, keepdim=<span class="literal">True</span>, unbiased=<span class="literal">False</span>)     <span class="comment"># 计算方差</span></span><br><span class="line">        x_hat = (x - mu) / torch.sqrt(var + <span class="variable language_">self</span>.eps)     <span class="comment"># 归一化</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.gamma * x_hat + <span class="variable language_">self</span>.beta             <span class="comment"># 缩放和平移</span></span><br></pre></td></tr></table></figure><hr><h2 id="RMSNorm"><a href="#RMSNorm" class="headerlink" title="RMSNorm"></a><strong>RMSNorm</strong></h2><p>近年来，许多大型语言模型（如 LLaMA、GPT-NeoX、PaLM）开始采用 RMSNorm（Root Mean Square Layer Normalization）替代传统的 LayerNorm，主要原因包括 计算效率更高、训练稳定性更好、对初始化敏感度更低</p><h3 id="①-计算方式-1"><a href="#①-计算方式-1" class="headerlink" title="① 计算方式"></a>① 计算方式</h3><p>RMSNorm 是 LayerNorm 的简化版本，由 <a href="https://arxiv.org/abs/1910.07467">Zhang &amp; Sennrich (2019)</a> 提出，其核心改进是 <strong>移除均值中心化（Mean Subtraction），仅对输入进行缩放（Scale）</strong>。  </p><p>具体计算步骤：</p><ol><li><strong>计算均方根（RMS）</strong>：<br>[<br>\text{RMS}(\mathbf{x}) &#x3D; \sqrt{\frac{1}{d} \sum_{i&#x3D;1}^d x_i^2 + \epsilon}<br>]<br>（其中 ( d ) 是 <code>hidden_dim</code>，( \epsilon ) 是小常数防止除零）</li><li><strong>归一化</strong>：<br>[<br>\hat{x}_i &#x3D; \frac{x_i}{\text{RMS}(\mathbf{x})}<br>]</li><li><strong>缩放</strong>（可学习参数）：<br>[<br>y_i &#x3D; \gamma_i \hat{x}_i<br>]<br>（注意：RMSNorm <strong>没有偏置项 ( \beta )</strong>）</li></ol><h3 id="②-具体例子-1"><a href="#②-具体例子-1" class="headerlink" title="② 具体例子"></a>② 具体例子</h3><p>假设我们有一个 <strong>单个样本</strong>（忽略 <code>batch_size</code> 和 <code>seq_len</code>），其 <code>hidden_dim=4</code>，输入向量为：<br>[<br>\mathbf{x} &#x3D; [1.0, 2.0, 3.0, 4.0]<br>]</p><ol><li><p><strong>计算均方根（RMS）</strong><br>[<br>\text{RMS}(\mathbf{x}) &#x3D; \sqrt{\frac{1}{4} (1.0^2 + 2.0^2 + 3.0^2 + 4.0^2)} &#x3D; \sqrt{\frac{1 + 4 + 9 + 16}{4}} &#x3D; \sqrt{7.5} \approx 2.7386<br>]<br>（假设 ( \epsilon &#x3D; 1e-5 ) 忽略不计）</p></li><li><p><strong>归一化</strong><br>[<br>\hat{x}_i &#x3D; \frac{x_i}{\text{RMS}(\mathbf{x})} \implies \hat{\mathbf{x}} \approx \left[ \frac{1.0}{2.7386}, \frac{2.0}{2.7386}, \frac{3.0}{2.7386}, \frac{4.0}{2.7386} \right] \approx [0.3651, 0.7303, 1.0954, 1.4606]<br>]</p></li><li><p><strong>缩放（假设可学习参数 ( \gamma &#x3D; [1, 1, 1, 1] )）</strong><br>[<br>\mathbf{y} &#x3D; \gamma \cdot \hat{\mathbf{x}} \approx [0.3651, 0.7303, 1.0954, 1.4606]<br>]</p></li></ol><h3 id="③-PyTorch实现-1"><a href="#③-PyTorch实现-1" class="headerlink" title="③ PyTorch实现"></a>③ PyTorch实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gamma = nn.Parameter(torch.ones(hidden_dim))  <span class="comment"># 仅缩放参数</span></span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        rms = torch.sqrt(x.<span class="built_in">pow</span>(<span class="number">2</span>).mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="variable language_">self</span>.eps  <span class="comment"># 计算 RMS</span></span><br><span class="line">        x_hat = x / rms                                  <span class="comment"># 归一化</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.gamma * x_hat                        <span class="comment"># 仅缩放</span></span><br></pre></td></tr></table></figure><hr><h1 id="二、Norm-对比"><a href="#二、Norm-对比" class="headerlink" title="二、Norm 对比"></a>二、Norm 对比</h1><h2 id="RMSNorm-对比-LayerNorm"><a href="#RMSNorm-对比-LayerNorm" class="headerlink" title="RMSNorm 对比 LayerNorm"></a><strong>RMSNorm 对比 LayerNorm</strong></h2><h3 id="关键差异"><a href="#关键差异" class="headerlink" title="关键差异"></a>关键差异</h3><table><thead><tr><th>操作</th><th>RMSNorm</th><th>LayerNorm</th></tr></thead><tbody><tr><td><strong>均值中心化</strong></td><td>❌ 不减去均值</td><td>✅ 减去均值</td></tr><tr><td><strong>分母</strong></td><td>均方根（RMS）</td><td>标准差（含均值中心化）</td></tr><tr><td><strong>可学习参数</strong></td><td>仅缩放（<code>gamma</code>）</td><td>缩放 + 平移（<code>gamma</code>, <code>beta</code>）</td></tr></tbody></table><h3 id="为什么-RMSNorm-更适合-LLM？"><a href="#为什么-RMSNorm-更适合-LLM？" class="headerlink" title="为什么 RMSNorm 更适合 LLM？"></a>为什么 RMSNorm 更适合 LLM？</h3><ol><li><strong>计算效率更高</strong><ul><li><strong>LayerNorm</strong> 需要计算均值（Mean）和方差（Variance），涉及两次逐元素操作（减均值、除标准差）。</li><li><strong>RMSNorm</strong> 仅需计算均方根（RMS），减少一次计算（无需减均值），**提速约 10%~20%**（对大规模模型显著）。</li></ul></li><li><strong>训练稳定性更好</strong><ul><li>LayerNorm 的均值中心化可能导致某些情况下梯度不稳定（尤其是初始化阶段或极端值出现时）。</li><li>RMSNorm 仅缩放输入，<strong>对初始化敏感度更低</strong>，实验显示在深层网络中更稳定。</li></ul></li><li><strong>性能无显著损失</strong><ul><li>论文实验表明，RMSNorm 在语言模型任务中与 LayerNorm 表现相当，甚至在某些场景下更优（如长序列建模）。  </li><li>例如，LLaMA-1&#x2F;2、GPT-NeoX 等模型均采用 RMSNorm，未观察到性能下降。</li></ul></li></ol><h3 id="关键区别总结"><a href="#关键区别总结" class="headerlink" title="关键区别总结"></a>关键区别总结</h3><table><thead><tr><th>特性</th><th>LayerNorm</th><th>RMSNorm</th></tr></thead><tbody><tr><td><strong>归一化方式</strong></td><td>减均值 + 除标准差</td><td>仅除均方根（RMS）</td></tr><tr><td><strong>可学习参数</strong></td><td><code>gamma</code> 和 <code>beta</code>（缩放+平移）</td><td>仅 <code>gamma</code>（缩放）</td></tr><tr><td><strong>计算复杂度</strong></td><td>较高（需计算均值和方差）</td><td>较低（仅计算 RMS）</td></tr><tr><td><strong>训练稳定性</strong></td><td>对初始化敏感</td><td>更稳定</td></tr><tr><td><strong>适用场景</strong></td><td>传统 Transformer &#x2F; 需要严格零均值的任务（如某些语音或图像模型）</td><td>大规模 LLM（如 LLaMA、GPT-NeoX）</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 归一化 </tag>
            
            <tag> LayerNorm </tag>
            
            <tag> RMSNorm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>windows永久暂停更新设置</title>
      <link href="/p/windows%E6%B0%B8%E4%B9%85%E6%9A%82%E5%81%9C%E6%9B%B4%E6%96%B0%E8%AE%BE%E7%BD%AE/"/>
      <url>/p/windows%E6%B0%B8%E4%B9%85%E6%9A%82%E5%81%9C%E6%9B%B4%E6%96%B0%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="如何暂停-Windows-更新：记录我的方法"><a href="#如何暂停-Windows-更新：记录我的方法" class="headerlink" title="如何暂停 Windows 更新：记录我的方法"></a>如何暂停 Windows 更新：记录我的方法</h1><p>在日常使用 Windows 系统的过程中，自动更新有时会带来一些不便，尤其是在关键时刻打断工作或占用系统资源。为了避免这种情况，我决定暂停 Windows 更新。以下是我记录的方法，供大家参考。</p><h2 id="方法步骤"><a href="#方法步骤" class="headerlink" title="方法步骤"></a>方法步骤</h2><h3 id="1-打开注册表编辑器"><a href="#1-打开注册表编辑器" class="headerlink" title="1. 打开注册表编辑器"></a>1. 打开注册表编辑器</h3><p>首先，我们需要打开 Windows 的注册表编辑器。按下 <code>Win + R</code> 组合键，输入 <code>regedit</code>，然后按下回车键。</p><h3 id="2-导航到指定路径"><a href="#2-导航到指定路径" class="headerlink" title="2. 导航到指定路径"></a>2. 导航到指定路径</h3><p>在注册表编辑器中，导航到以下路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">计算机\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\WindowsUpdate\UX\Settings</span><br></pre></td></tr></table></figure><h3 id="3-新建-DWORD-32-位-值"><a href="#3-新建-DWORD-32-位-值" class="headerlink" title="3. 新建 DWORD (32 位) 值"></a>3. 新建 DWORD (32 位) 值</h3><p>在 <code>Settings</code> 文件夹中，右键点击空白处，选择 <code>新建</code> -&gt; <code>DWORD (32 位) 值</code>。将新建的值命名为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FlightSettingsMaxPauseDays</span><br></pre></td></tr></table></figure><h3 id="4-修改取值"><a href="#4-修改取值" class="headerlink" title="4. 修改取值"></a>4. 修改取值</h3><p>双击刚刚创建的 <code>FlightSettingsMaxPauseDays</code>，将其值修改为 <code>35000</code>（十进制）。这个值表示 35000 天（5000周），即大约 100 年。</p><h3 id="5-保存并退出"><a href="#5-保存并退出" class="headerlink" title="5. 保存并退出"></a>5. 保存并退出</h3><p>完成上述操作后，点击 <code>确定</code> 保存更改，然后关闭注册表编辑器。</p><h3 id="6-修改-Windows-更新设置"><a href="#6-修改-Windows-更新设置" class="headerlink" title="6. 修改 Windows 更新设置"></a>6. 修改 Windows 更新设置</h3><p>最后，打开 <code>设置</code> -&gt; <code>Windows 更新</code>，在更新设置中修改暂停更新的周数。此时，你应该可以看到暂停更新的时间已经被大幅延长。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li><strong>谨慎操作</strong>：错误修改注册表可能会对系统稳定性产生影响，建议在操作时小心谨慎，切勿修改其他配置。（小白最好能先备份再修改）</li><li><strong>定期检查</strong>：虽然暂停更新可以避免不必要的打扰，但为了系统的安全性，建议定期手动检查并安装重要的安全更新。</li></ul><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>通过以上步骤，我成功暂停了 Windows 更新，避免了系统在关键时刻被打扰。</p><hr><p><strong>标签</strong>: #Windows #系统优化 #暂停更新 #注册表修改</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> windows </tag>
            
            <tag> 系统优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python中的图片基础操作</title>
      <link href="/p/python%E4%B8%AD%E7%9A%84%E5%9B%BE%E7%89%87%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/"/>
      <url>/p/python%E4%B8%AD%E7%9A%84%E5%9B%BE%E7%89%87%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="PIL-pillow"><a href="#PIL-pillow" class="headerlink" title="PIL (pillow)"></a>PIL (pillow)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="基础读写"><a href="#基础读写" class="headerlink" title="基础读写"></a>基础读写</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取图片</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(<span class="string">&#x27;/path/to/image.png&#x27;</span>).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">image2 = Image.<span class="built_in">open</span>(io.BytesIO(buffer))  <span class="comment"># buffer is bytes</span></span><br><span class="line">image3 = Image.<span class="built_in">open</span>(requests.get(image_url, stream=<span class="literal">True</span>).raw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看图像实例的属性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Format: &#123;image.format&#125;</span></span><br><span class="line"><span class="string">Size: &#123;image.size&#125; = (width, height)</span></span><br><span class="line"><span class="string">Mode: &#123;image.mode&#125; ∈ (L, RGB, RGBA, CMYK, YCbCr, HSV)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line">image.save(<span class="string">&#x27;/path/to/image.jpg&#x27;</span>, <span class="string">&#x27;jpg&#x27;</span>)  <span class="comment"># 有损压缩存储</span></span><br><span class="line">image.save(<span class="string">&#x27;/path/to/image.phg&#x27;</span>, <span class="string">&#x27;png&#x27;</span>)  <span class="comment"># 无损存储</span></span><br></pre></td></tr></table></figure><h2 id="展示图片"><a href="#展示图片" class="headerlink" title="展示图片"></a>展示图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_one_image</span>(<span class="params">image</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(image, <span class="built_in">str</span>):</span><br><span class="line">        image = Image.<span class="built_in">open</span>(image).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">    plt.imshow(image); plt.axis(<span class="string">&#x27;off&#x27;</span>); plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_images</span>(<span class="params">image_files</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(image_files) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义每张图片的最大宽度和高度</span></span><br><span class="line">    max_width, max_height = <span class="number">224</span>, <span class="number">224</span></span><br><span class="line">    <span class="comment"># 打开并缩放图片</span></span><br><span class="line">    images = []</span><br><span class="line">    <span class="keyword">for</span> img_file <span class="keyword">in</span> image_files:</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_file)</span><br><span class="line">        img = img.resize((max_width, max_height), Image.BILINEAR)</span><br><span class="line">        images.append(img)</span><br><span class="line">    <span class="comment"># 计算拼接后的总宽度和高度</span></span><br><span class="line">    total_width = <span class="built_in">sum</span>(img.width <span class="keyword">for</span> img <span class="keyword">in</span> images)</span><br><span class="line">    max_height = <span class="built_in">max</span>(img.height <span class="keyword">for</span> img <span class="keyword">in</span> images)</span><br><span class="line">    <span class="comment"># 创建新的空白图片</span></span><br><span class="line">    new_image = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (total_width, max_height))</span><br><span class="line">    <span class="comment"># 拼接图片</span></span><br><span class="line">    x_offset = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">        new_image.paste(img, (x_offset, <span class="number">0</span>))</span><br><span class="line">        x_offset += img.width</span><br><span class="line">    <span class="comment"># 在Jupyter Notebook中展示拼接后的图片</span></span><br><span class="line">    plt.imshow(new_image); plt.axis(<span class="string">&#x27;off&#x27;</span>); plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_show_dir_images</span>(<span class="params">dirname, k=<span class="number">5</span></span>):</span><br><span class="line">    <span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line">    <span class="keyword">import</span> random</span><br><span class="line">    fnames = glob(dirname.rstrip(<span class="string">&#x27;/&#x27;</span>)+<span class="string">&#x27;/*.jpg&#x27;</span>) + glob(dirname.rstrip(<span class="string">&#x27;/&#x27;</span>)+<span class="string">&#x27;/*.jpeg&#x27;</span>) + glob(dirname.rstrip(<span class="string">&#x27;/&#x27;</span>)+<span class="string">&#x27;/*.png&#x27;</span>)</span><br><span class="line">    show_images(random.choices(fnames, k=k))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图片强制缩放到224x224</span></span><br><span class="line">img = img.resize((<span class="number">224</span>,<span class="number">224</span>), Image.BILINEAR)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 图片 </tag>
            
            <tag> PIL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bash常用配置</title>
      <link href="/p/Bash%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/"/>
      <url>/p/Bash%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! vi /etc/profile 或 vi ~/.bashrc</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># alias</span></span><br><span class="line"><span class="built_in">alias</span> ll=<span class="string">&quot;ls -alh&quot;</span></span><br><span class="line"><span class="built_in">alias</span> du1=<span class="string">&quot;du --max-depth=1&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># inputrc</span></span><br><span class="line"><span class="built_in">bind</span> <span class="string">&#x27;&quot;\C-p&quot;: history-search-backward&#x27;</span></span><br><span class="line"><span class="built_in">bind</span> <span class="string">&#x27;&quot;\C-n&quot;: history-search-forward&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ollama使用教程</title>
      <link href="/p/ollama%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
      <url>/p/ollama%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --cpus=<span class="string">&quot;8.0&quot;</span> --memory=<span class="string">&quot;16g&quot;</span> -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama  <span class="comment"># 加速docker.1ms.run</span></span><br></pre></td></tr></table></figure><h1 id="拉取模型"><a href="#拉取模型" class="headerlink" title="拉取模型"></a>拉取模型</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it ollama    ollama pull qwen2.5:3b</span><br></pre></td></tr></table></figure><h1 id="对话交互"><a href="#对话交互" class="headerlink" title="对话交互"></a>对话交互</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it ollama    ollama run qwen2.5:3b</span><br></pre></td></tr></table></figure><h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看ollama版本</span></span><br><span class="line">curl http://localhost:11434/api/version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看本地模型</span></span><br><span class="line">curl http://localhost:11434/api/tags</span><br><span class="line"><span class="comment"># 查看当前加载进内存的模型</span></span><br><span class="line">curl http://localhost:11434/api/ps</span><br><span class="line"><span class="comment"># 查看模型信息</span></span><br><span class="line">curl http://localhost:11434/api/show -d <span class="string">&#x27;&#123;&quot;model&quot;: &quot;llama3.2&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加模型（远程拉取模型）</span></span><br><span class="line">curl http://localhost:11434/api/pull -d <span class="string">&#x27;&#123;&quot;model&quot;: &quot;llama3:13b&quot;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 删除模型（从本地删除）</span></span><br><span class="line">curl -X DELETE http://localhost:11434/api/delete -d <span class="string">&#x27;&#123;&quot;model&quot;: &quot;llama3:13b&quot;&#125;&#x27;</span></span><br><span class="line"><span class="comment"># 复制模型（从已存在的模型中，复制出一个名字不同的相同模型）</span></span><br><span class="line">curl http://localhost:11434/api/copy -d <span class="string">&#x27;&#123;&quot;source&quot;: &quot;llama3.2&quot;,  &quot;destination&quot;: &quot;llama3.2-backup&quot;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成Embedding</span></span><br><span class="line">curl http://localhost:11434/api/embed -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;all-minilm&quot;,</span></span><br><span class="line"><span class="string">  &quot;input&quot;: &quot;Why is the sky blue?&quot;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本补全</span></span><br><span class="line">curl http://localhost:11434/api/generate -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;llama3.2&quot;,</span></span><br><span class="line"><span class="string">  &quot;stream&quot;: false,</span></span><br><span class="line"><span class="string">  &quot;options&quot;: &#123;&quot;temperature&quot;: 0, &quot;seed&quot;: 123&#125;,</span></span><br><span class="line"><span class="string">  &quot;prompt&quot;: &quot;Why is the sky blue?&quot;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对话聊天</span></span><br><span class="line">curl http://localhost:11434/api/chat -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;llama3.2&quot;,</span></span><br><span class="line"><span class="string">  &quot;stream&quot;: false,</span></span><br><span class="line"><span class="string">  &quot;options&quot;: &#123;&quot;temperature&quot;: 0.7, &quot;seed&quot;: 123&#125;,</span></span><br><span class="line"><span class="string">  &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;role&quot;: &quot;user&quot;,</span></span><br><span class="line"><span class="string">      &quot;content&quot;: &quot;why is the sky blue?&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/ollama/ollama/tree/main">ollama&#x2F;ollama: Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.</a></li><li><a href="https://hub.docker.com/r/ollama/ollama">ollama&#x2F;ollama - Docker Image | Docker Hub</a></li><li><a href="https://github.com/ollama/ollama/blob/main/docs/api.md#endpoints">ollama&#x2F;docs&#x2F;api.md at main · ollama&#x2F;ollama</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
            <tag> ollama </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet-18的torch实现源码解读</title>
      <link href="/p/ResNet-18%E7%9A%84torch%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
      <url>/p/ResNet-18%E7%9A%84torch%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="ResNet-18的torch实现源码解读"><a href="#ResNet-18的torch实现源码解读" class="headerlink" title="ResNet-18的torch实现源码解读"></a>ResNet-18的torch实现源码解读</h1><ul><li><p>Input: 3x224x224</p></li><li><p>Layer-0: conv1 + bn1 + relu + maxpool</p><ul><li>conv1: 3-&gt;64通道。上下左右补3像素，卷积核7x7，步长2像素(尺寸减半112x112)。没有偏置项</li><li>bn1+relu: 先批归一化，再激活</li><li>maxpool: 上下左右补1像素，池化核3x3，步长为2(尺寸再减半56x56)</li></ul></li><li><p>Layer-1: self._make_layer(block, 64, layers[0])</p><ol><li>BasicBlock-1<ul><li><p>conv1: 64-&gt;64通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 64-&gt;64通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸没变，因此直接相加即可(&#x3D;本Block的输入+bn2的输出)</p></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li><li>BasicBlock-2<ul><li><p>conv1: 64-&gt;64通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 64-&gt;64通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸没变，因此直接相加即可(&#x3D;本Block的输入+bn2的输出)</p></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li></ol></li><li><p>Layer-2: self._make_layer(block, 128, layers[1], stride&#x3D;2, dilate&#x3D;replace_stride_with_dilation[0])</p><ol><li><p>BasicBlock-1</p><ul><li><p>conv1: 64-&gt;128通道。上下左右补1像素，卷积核3x3，步长2像素(尺寸减半28x28)。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 128-&gt;128通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸变化，因此要将本Block的输入做1x1卷积后，使得和bn2的输出相同尺寸后，再相加)</p><ul><li>downsample<ul><li>对本Block的输入：64-&gt;128通道。做1x1卷积变换，步长2像素(尺寸减半28x28)。没有偏置项</li><li>批归一化</li></ul></li></ul></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li><li><p>BasicBlock-2</p><ul><li><p>conv1: 128-&gt;128通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 128-&gt;128通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸没变，因此直接相加即可(&#x3D;本Block的输入+bn2的输出)</p></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li></ol></li><li><p>Layer-3: self._make_layer(block, 256, layers[2], stride&#x3D;2, dilate&#x3D;replace_stride_with_dilation[1])</p><ol><li><p>BasicBlock-1</p><ul><li><p>conv1: 128-&gt;256通道。上下左右补1像素，卷积核3x3，步长2像素(尺寸减半14x14)。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 256-&gt;256通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸变化，因此要将本Block的输入做1x1卷积后，使得和bn2的输出相同尺寸后，再相加)</p><ul><li>downsample<ul><li>对本Block的输入：128-&gt;256通道。做1x1卷积变换，步长2像素(尺寸减半14x14)。没有偏置项</li><li>批归一化</li></ul></li></ul></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li><li><p>BasicBlock-2</p><ul><li><p>conv1: 256-&gt;256通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 256-&gt;256通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸没变，因此直接相加即可(&#x3D;本Block的输入+bn2的输出)</p></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li></ol></li><li><p>Layer-4: self._make_layer(block, 512, layers[3], stride&#x3D;2, dilate&#x3D;replace_stride_with_dilation[2])</p><ol><li><p>BasicBlock-1</p><ul><li><p>conv1: 256-&gt;512通道。上下左右补1像素，卷积核3x3，步长2像素(尺寸减半7x7)。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 512-&gt;512通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸变化，因此要将本Block的输入做1x1卷积后，使得和bn2的输出相同尺寸后，再相加)</p><ul><li>downsample<ul><li>对本Block的输入：256-&gt;512通道。做1x1卷积变换，步长2像素(尺寸减半7x7)。没有偏置项</li><li>批归一化</li></ul></li></ul></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li><li><p>BasicBlock-2</p><ul><li><p>conv1: 512-&gt;512通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn1+relu: 先批归一化，再激活</p></li><li><p>conv2: 512-&gt;512通道。上下左右补1像素，卷积核3x3，步长1像素。没有偏置项</p></li><li><p>bn2: 批归一化</p></li><li><p>残差连接: 由于特征图尺寸没变，因此直接相加即可(&#x3D;本Block的输入+bn2的输出)</p></li><li><p>relu: 最后relu激活（先残差后激活）</p></li></ul></li></ol></li><li><p>Layer-fc: </p><ol><li>avgpool: nn.AdaptiveAvgPool2d((1, 1))保持通道数不变，将每个特征图平均池化为1x1尺寸</li><li>flatten: torch.flatten(x, 1) 从维度1开始往后flatten，也就是将shape从(bs, 512, 1, 1)——&gt;(bs, 512)</li><li>fc: 最后将512映射为num_classes维度</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> resnet </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跨平台框架React Native(Expo)学习笔记</title>
      <link href="/p/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6React%20Native(Expo)%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/p/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%A1%86%E6%9E%B6React%20Native(Expo)%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="开发环境设置"><a href="#开发环境设置" class="headerlink" title="开发环境设置"></a>开发环境设置</h1><ol><li>安装 Node.js LTS版</li><li>在安卓&#x2F;iOS手机上安装Expo Go应用</li></ol><h1 id="开发第一个app"><a href="#开发第一个app" class="headerlink" title="开发第一个app"></a>开发第一个app</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">npx create<span class="literal">-expo-app</span>@latest StickerSmash &amp;&amp; <span class="built_in">cd</span> StickerSmash  <span class="comment"># 初始化新的Expo应用程序</span></span><br><span class="line"><span class="comment"># wget https://docs.expo.dev/static/images/tutorial/sticker-smash-assets.zip &amp;&amp; unzip sticker-smash-assets.zip &amp;&amp; mv sticker-smash-assets/* ./assets/images</span></span><br><span class="line">npm run <span class="built_in">reset-project</span>   <span class="comment"># 重置项目(删除里面的示例模板代码)</span></span><br><span class="line">npx expo <span class="built_in">start</span>  <span class="comment"># 开发服务器启动后，用手机上的ExpoGo扫描屏幕上的二维码</span></span><br></pre></td></tr></table></figure><p><img src="https://docs.expo.dev/static/images/tutorial/01-app-running-on-all-platforms.png" alt="一旦它在所有平台上运行，应用程序应该看起来像这样"></p><h1 id="简单修改app"><a href="#简单修改app" class="headerlink" title="简单修改app"></a>简单修改app</h1><p>让我们修改<code>app/index.tsx</code>:</p><ol><li>从react-native导入StyleSheet并创建一个styles对象来定义我们的自定义样式</li><li>向<View>添加值为#25292e的 styles.container.backgroundColor 属性。这会改变背景颜色</li><li>将<Text>的默认值替换为“Home Screen”</li><li>向<Text>添加值为#fff（白色）的styles.text.color属性以更改文本颜色</li></ol><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">Text</span>, <span class="title class_">View</span>,  <span class="title class_">StyleSheet</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;  <span class="comment">// add StyleSheet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">Index</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.text&#125;</span>&gt;</span>Home screen<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>   // add</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">  <span class="attr">container</span>: &#123;</span><br><span class="line">    <span class="attr">flex</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">backgroundColor</span>: <span class="string">&#x27;#25292e&#x27;</span>,    <span class="comment">// add</span></span><br><span class="line">    <span class="attr">alignItems</span>: <span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">    <span class="attr">justifyContent</span>: <span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">text</span>: &#123;</span><br><span class="line">    <span class="attr">color</span>: <span class="string">&#x27;#fff&#x27;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><img src="https://docs.expo.dev/static/images/tutorial/02-index-screen-changes.png" alt="黑色背景"></p><h1 id="添加导航"><a href="#添加导航" class="headerlink" title="添加导航"></a>添加导航</h1><p>TODO</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://docs.expo.dev/tutorial/create-your-first-app/">Create your first app  创建您的第一个应用程序</a></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
            <tag> React Native </tag>
            
            <tag> Expo </tag>
            
            <tag> Android </tag>
            
            <tag> iOS </tag>
            
            <tag> Web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>免费翻译API</title>
      <link href="/p/%E5%85%8D%E8%B4%B9%E7%BF%BB%E8%AF%91API/"/>
      <url>/p/%E5%85%8D%E8%B4%B9%E7%BF%BB%E8%AF%91API/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_tran</span>(<span class="params">text,source_lang=<span class="string">&quot;&quot;</span>,target_lang=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    调用 https://findmyip.net/api/translate.php 接口 翻译文本</span></span><br><span class="line"><span class="string">    :param text:需要翻译的源文本</span></span><br><span class="line"><span class="string">    :param source_lang:源文本语言种类（此参数若不填写，将会进行自动检测）</span></span><br><span class="line"><span class="string">    :param target_lang:翻译后的语言种类（此参数若不填写，将会自动翻译成中文）</span></span><br><span class="line"><span class="string">    :return: 翻译后的内容</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    url=<span class="string">f&quot;https://findmyip.net/api/translate.php?text=<span class="subst">&#123;text&#125;</span>&amp;source_lang=<span class="subst">&#123;source_lang&#125;</span>&amp;target_lang=<span class="subst">&#123;target_lang&#125;</span>&quot;</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    result=response.json()[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;translate_result&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">google_translate</span>(<span class="params">q, src_lang=<span class="string">&#x27;zh-CN&#x27;</span>, tgt_lang=<span class="string">&#x27;en&#x27;</span>, host=<span class="string">&#x27;tl.faison.cc&#x27;</span>, debug=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 调用google翻译接口</span></span><br><span class="line"><span class="string">    src_lang: 初始语言</span></span><br><span class="line"><span class="string">    tgt_lang：目标语言</span></span><br><span class="line"><span class="string">    host：google翻译域名的反代域名，用于解决国内不能直接访问google</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> q.strip():</span><br><span class="line">        <span class="keyword">return</span> q</span><br><span class="line">    <span class="keyword">import</span> requests</span><br><span class="line">    <span class="comment"># response = requests.get(&#x27;https://tl.faison.cc/translate_a/single?client=gtx&amp;sl=zh-CN&amp;tl=en&amp;dt=t&amp;q=你好,中国&#x27;)</span></span><br><span class="line">    params = &#123;<span class="string">&#x27;client&#x27;</span>: <span class="string">&#x27;gtx&#x27;</span>, <span class="string">&#x27;sl&#x27;</span>: src_lang, <span class="string">&#x27;tl&#x27;</span>: tgt_lang, <span class="string">&#x27;dt&#x27;</span>: <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;q&#x27;</span>: q&#125;</span><br><span class="line">    resp = requests.get(<span class="string">f&#x27;https://<span class="subst">&#123;host&#125;</span>/translate_a/single&#x27;</span>, params=params)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span> <span class="keyword">and</span> resp.headers[<span class="string">&#x27;Content-Type&#x27;</span>].startswith(<span class="string">&#x27;application/json&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(one[<span class="number">0</span>] <span class="keyword">for</span> one <span class="keyword">in</span> resp.json()[<span class="number">0</span>]) <span class="keyword">if</span> <span class="keyword">not</span> debug <span class="keyword">else</span> debug</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">f&quot;&quot;&quot;resp.status_code == <span class="subst">&#123;resp.status_code&#125;</span>\nresp.headers[&#x27;Content-Type&#x27;]=<span class="subst">&#123;resp.headers[<span class="string">&#x27;Content-Type&#x27;</span>]&#125;</span>\nresp.text=<span class="subst">&#123;resp.text&#125;</span>&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(google_translate(<span class="string">&#x27;你好,中国&#x27;</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %pip install pygoogletranslation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ggtranslate</span>(<span class="params">line, src=<span class="string">&#x27;en&#x27;</span>, dest=<span class="string">&#x27;zh-cn&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">from</span> googletrans <span class="keyword">import</span> Translator</span><br><span class="line">    <span class="comment"># 使用Google翻译API</span></span><br><span class="line">    translator = Translator(service_urls=[<span class="string">&#x27;tl.faison.cc&#x27;</span>, <span class="string">&#x27;translate.google.cn&#x27;</span>,])</span><br><span class="line">    <span class="comment">#translator.raise_Exception = lambda x: x</span></span><br><span class="line">    <span class="keyword">if</span> line.strip():</span><br><span class="line">        trans = translator.translate(line, src=src, dest=dest)</span><br><span class="line">        <span class="keyword">return</span> trans.text</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> line</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(ggtranslate(<span class="string">&#x27;hello, china&#x27;</span>))</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://cloud.tencent.com/developer/article/2406974">Python实例教程，谷歌翻译接口API调用方法技巧！-腾讯云开发者社区-腾讯云</a></li><li><a href="https://zhpengfei.com/cloudflare-worker-proxy-google-translate/">[亲测有效]使用 Cloudflare Worker 代理谷歌翻译和 API，绕过限制，实现国内加速访问</a></li><li><a href="https://juejin.cn/post/6986599019782864933">如何用Python一次性翻译十万条数据</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>docker教程</title>
      <link href="/p/docker%E6%95%99%E7%A8%8B/"/>
      <url>/p/docker%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 卸载旧版本docker</span></span><br><span class="line">yum remove docker \</span><br><span class="line">    docker-client \</span><br><span class="line">    docker-client-latest \</span><br><span class="line">    docker-common \</span><br><span class="line">    docker-latest \</span><br><span class="line">    docker-latest-logrotate \</span><br><span class="line">    docker-logrotate \</span><br><span class="line">    docker-engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 安装docker的yum库</span></span><br><span class="line">yum install -y yum-utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 配置docker的yum源</span></span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 安装docker</span></span><br><span class="line">yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line">docker -v  <span class="comment"># 检查是否安装成功</span></span><br><span class="line">docker images  <span class="comment"># 检查是否启动了docker服务</span></span><br><span class="line"><span class="comment"># 安装docker后，默认docker0占用172.17.0.0网段（route -n），如果内网的其他服务器有使用这个网段，需要修改docker0占用的网段到其他网段（如192.168.x.x）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 启动和校验docker</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker  <span class="comment"># 开机自启</span></span><br><span class="line">systemctl start docker  <span class="comment"># 首次手动开启</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 后续管理</span></span><br><span class="line">systemctl stop docker</span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 用户加入docker组</span></span><br><span class="line"><span class="built_in">sudo</span> usermod -aG docker your_username</span><br></pre></td></tr></table></figure><h1 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h1><h2 id="随便找个国内源"><a href="#随便找个国内源" class="headerlink" title="随便找个国内源"></a>随便找个国内源</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">```bash</span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入上面那个目录后再依次执行下面的命令</span></span><br><span class="line"><span class="comment"># 复制内容，注意把其中的镜像加速地址改成你自己的</span></span><br><span class="line"><span class="built_in">tee</span> /etc/docker/daemon.json &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://xxxx.mirror.aliyuncs.com&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新加载配置</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启Docker</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="自建：CF反代官方源"><a href="#自建：CF反代官方源" class="headerlink" title="自建：CF反代官方源"></a>自建：CF反代官方源</h2><ol><li>CF新建worker，用下面连接的代码替换示例代码即可<ol><li><a href="https://github.com/jonssonyan/cf-workers-proxy/blob/main/docker.js">https://github.com/jonssonyan/cf-workers-proxy/blob/main/docker.js</a></li></ol></li><li>绑定自定义域名（子域名就行）</li><li>如果是cloudns的域名，去cloudns上新增A地址指向CF的ip（如：172.67.42.76），等上面转圈结束即可</li><li>使docker生效<ol><li>修改&#x2F;etc&#x2F;docker&#x2F;daemon.json文件，添加 <code>&quot;registry-mirrors&quot;: [&quot;https://xxxx.mirror.aliyuncs.com&quot;]</code></li><li>重载配置并重启docker：<code>systemctl daemon-reload &amp;&amp; systemctl restart docker</code></li></ol></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">logError</span>(<span class="params">request, message</span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">error</span>(</span><br><span class="line">    <span class="string">`<span class="subst">$&#123;message&#125;</span>, clientIp: <span class="subst">$&#123;request.headers.get(</span></span></span><br><span class="line"><span class="subst"><span class="string">      <span class="string">&quot;cf-connecting-ip&quot;</span></span></span></span><br><span class="line"><span class="subst"><span class="string">    )&#125;</span>, user-agent: <span class="subst">$&#123;request.headers.get(<span class="string">&quot;user-agent&quot;</span>)&#125;</span>, url: <span class="subst">$&#123;request.url&#125;</span>`</span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">createNewRequest</span>(<span class="params">request, url, proxyHostname, originHostname</span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> newRequestHeaders = <span class="keyword">new</span> <span class="title class_">Headers</span>(request.<span class="property">headers</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> [key, value] <span class="keyword">of</span> newRequestHeaders) &#123;</span><br><span class="line">    <span class="keyword">if</span> (value.<span class="title function_">includes</span>(originHostname)) &#123;</span><br><span class="line">      newRequestHeaders.<span class="title function_">set</span>(</span><br><span class="line">        key,</span><br><span class="line">        value.<span class="title function_">replace</span>(</span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="string">`(?&lt;!\\.)\\b<span class="subst">$&#123;originHostname&#125;</span>\\b`</span>, <span class="string">&quot;g&quot;</span>),</span><br><span class="line">          proxyHostname</span><br><span class="line">        )</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Request</span>(url.<span class="title function_">toString</span>(), &#123;</span><br><span class="line">    <span class="attr">method</span>: request.<span class="property">method</span>,</span><br><span class="line">    <span class="attr">headers</span>: newRequestHeaders,</span><br><span class="line">    <span class="attr">body</span>: request.<span class="property">body</span>,</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">setResponseHeaders</span>(<span class="params"></span></span><br><span class="line"><span class="params">  originalResponse,</span></span><br><span class="line"><span class="params">  proxyHostname,</span></span><br><span class="line"><span class="params">  originHostname,</span></span><br><span class="line"><span class="params">  DEBUG</span></span><br><span class="line"><span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> newResponseHeaders = <span class="keyword">new</span> <span class="title class_">Headers</span>(originalResponse.<span class="property">headers</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> [key, value] <span class="keyword">of</span> newResponseHeaders) &#123;</span><br><span class="line">    <span class="keyword">if</span> (value.<span class="title function_">includes</span>(proxyHostname)) &#123;</span><br><span class="line">      newResponseHeaders.<span class="title function_">set</span>(</span><br><span class="line">        key,</span><br><span class="line">        value.<span class="title function_">replace</span>(</span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="string">`(?&lt;!\\.)\\b<span class="subst">$&#123;proxyHostname&#125;</span>\\b`</span>, <span class="string">&quot;g&quot;</span>),</span><br><span class="line">          originHostname</span><br><span class="line">        )</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (<span class="variable constant_">DEBUG</span>) &#123;</span><br><span class="line">    newResponseHeaders.<span class="title function_">delete</span>(<span class="string">&quot;content-security-policy&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">let</span> docker_auth_url = newResponseHeaders.<span class="title function_">get</span>(<span class="string">&quot;www-authenticate&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span> (docker_auth_url &amp;&amp; docker_auth_url.<span class="title function_">includes</span>(<span class="string">&quot;auth.docker.io/token&quot;</span>)) &#123;</span><br><span class="line">    newResponseHeaders.<span class="title function_">set</span>(</span><br><span class="line">      <span class="string">&quot;www-authenticate&quot;</span>,</span><br><span class="line">      docker_auth_url.<span class="title function_">replace</span>(<span class="string">&quot;auth.docker.io/token&quot;</span>, originHostname + <span class="string">&quot;/token&quot;</span>)</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> newResponseHeaders;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 替换内容</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> originalResponse 响应</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> proxyHostname 代理地址 hostname</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> pathnameRegex 代理地址路径匹配的正则表达式</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> originHostname 替换的字符串</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@returns</span> &#123;<span class="type">Promise&lt;*&gt;</span>&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">replaceResponseText</span>(<span class="params"></span></span><br><span class="line"><span class="params">  originalResponse,</span></span><br><span class="line"><span class="params">  proxyHostname,</span></span><br><span class="line"><span class="params">  pathnameRegex,</span></span><br><span class="line"><span class="params">  originHostname</span></span><br><span class="line"><span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">let</span> text = <span class="keyword">await</span> originalResponse.<span class="title function_">text</span>();</span><br><span class="line">  <span class="keyword">if</span> (pathnameRegex) &#123;</span><br><span class="line">    pathnameRegex = pathnameRegex.<span class="title function_">replace</span>(<span class="regexp">/^\^/</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> text.<span class="title function_">replace</span>(</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="string">`((?&lt;!\\.)\\b<span class="subst">$&#123;proxyHostname&#125;</span>\\b)(<span class="subst">$&#123;pathnameRegex&#125;</span>)`</span>, <span class="string">&quot;g&quot;</span>),</span><br><span class="line">      <span class="string">`<span class="subst">$&#123;originHostname&#125;</span>$2`</span></span><br><span class="line">    );</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> text.<span class="title function_">replace</span>(</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="string">`(?&lt;!\\.)\\b<span class="subst">$&#123;proxyHostname&#125;</span>\\b`</span>, <span class="string">&quot;g&quot;</span>),</span><br><span class="line">      originHostname</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">nginx</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="string">`&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="string">&lt;html&gt;</span></span><br><span class="line"><span class="string">&lt;head&gt;</span></span><br><span class="line"><span class="string">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span></span><br><span class="line"><span class="string">&lt;style&gt;</span></span><br><span class="line"><span class="string">html &#123; color-scheme: light dark; &#125;</span></span><br><span class="line"><span class="string">body &#123; width: 35em; margin: 0 auto;</span></span><br><span class="line"><span class="string">font-family: Tahoma, Verdana, Arial, sans-serif; &#125;</span></span><br><span class="line"><span class="string">&lt;/style&gt;</span></span><br><span class="line"><span class="string">&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span></span><br><span class="line"><span class="string">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span></span><br><span class="line"><span class="string">working. Further configuration is required.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p&gt;For online documentation and support please refer to</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span></span><br><span class="line"><span class="string">Commercial support is available at</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;/body&gt;</span></span><br><span class="line"><span class="string">&lt;/html&gt;`</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  <span class="keyword">async</span> <span class="title function_">fetch</span>(<span class="params">request, env, ctx</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">let</span> &#123;</span><br><span class="line">        <span class="variable constant_">PROXY_HOSTNAME</span> = <span class="string">&quot;registry-1.docker.io&quot;</span>,</span><br><span class="line">        <span class="variable constant_">PROXY_PROTOCOL</span> = <span class="string">&quot;https&quot;</span>,</span><br><span class="line">        <span class="variable constant_">PATHNAME_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">UA_WHITELIST_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">UA_BLACKLIST_REGEX</span>,</span><br><span class="line">        <span class="title class_">URL302</span>,</span><br><span class="line">        <span class="variable constant_">IP_WHITELIST_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">IP_BLACKLIST_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">REGION_WHITELIST_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">REGION_BLACKLIST_REGEX</span>,</span><br><span class="line">        <span class="variable constant_">DEBUG</span> = <span class="literal">false</span>,</span><br><span class="line">      &#125; = env;</span><br><span class="line">      <span class="keyword">const</span> url = <span class="keyword">new</span> <span class="title function_">URL</span>(request.<span class="property">url</span>);</span><br><span class="line">      <span class="keyword">const</span> originHostname = url.<span class="property">hostname</span>;</span><br><span class="line">      <span class="keyword">if</span> (url.<span class="property">pathname</span>.<span class="title function_">includes</span>(<span class="string">&quot;/token&quot;</span>)) &#123;</span><br><span class="line">        <span class="variable constant_">PROXY_HOSTNAME</span> = <span class="string">&quot;auth.docker.io&quot;</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (url.<span class="property">pathname</span>.<span class="title function_">includes</span>(<span class="string">&quot;/search&quot;</span>)) &#123;</span><br><span class="line">        <span class="variable constant_">PROXY_HOSTNAME</span> = <span class="string">&quot;index.docker.io&quot;</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (</span><br><span class="line">        !<span class="variable constant_">PROXY_HOSTNAME</span> ||</span><br><span class="line">        (<span class="variable constant_">PATHNAME_REGEX</span> &amp;&amp; !<span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">PATHNAME_REGEX</span>).<span class="title function_">test</span>(url.<span class="property">pathname</span>)) ||</span><br><span class="line">        (<span class="variable constant_">UA_WHITELIST_REGEX</span> &amp;&amp;</span><br><span class="line">          !<span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">UA_WHITELIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;user-agent&quot;</span>).<span class="title function_">toLowerCase</span>()</span><br><span class="line">          )) ||</span><br><span class="line">        (<span class="variable constant_">UA_BLACKLIST_REGEX</span> &amp;&amp;</span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">UA_BLACKLIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;user-agent&quot;</span>).<span class="title function_">toLowerCase</span>()</span><br><span class="line">          )) ||</span><br><span class="line">        (<span class="variable constant_">IP_WHITELIST_REGEX</span> &amp;&amp;</span><br><span class="line">          !<span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">IP_WHITELIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;cf-connecting-ip&quot;</span>)</span><br><span class="line">          )) ||</span><br><span class="line">        (<span class="variable constant_">IP_BLACKLIST_REGEX</span> &amp;&amp;</span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">IP_BLACKLIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;cf-connecting-ip&quot;</span>)</span><br><span class="line">          )) ||</span><br><span class="line">        (<span class="variable constant_">REGION_WHITELIST_REGEX</span> &amp;&amp;</span><br><span class="line">          !<span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">REGION_WHITELIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;cf-ipcountry&quot;</span>)</span><br><span class="line">          )) ||</span><br><span class="line">        (<span class="variable constant_">REGION_BLACKLIST_REGEX</span> &amp;&amp;</span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">RegExp</span>(<span class="variable constant_">REGION_BLACKLIST_REGEX</span>).<span class="title function_">test</span>(</span><br><span class="line">            request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&quot;cf-ipcountry&quot;</span>)</span><br><span class="line">          ))</span><br><span class="line">      ) &#123;</span><br><span class="line">        <span class="title function_">logError</span>(request, <span class="string">&quot;Invalid&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="title class_">URL302</span></span><br><span class="line">          ? <span class="title class_">Response</span>.<span class="title function_">redirect</span>(<span class="title class_">URL302</span>, <span class="number">302</span>)</span><br><span class="line">          : <span class="keyword">new</span> <span class="title class_">Response</span>(<span class="keyword">await</span> <span class="title function_">nginx</span>(), &#123;</span><br><span class="line">              <span class="attr">headers</span>: &#123;</span><br><span class="line">                <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;text/html; charset=utf-8&quot;</span>,</span><br><span class="line">              &#125;,</span><br><span class="line">            &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">      url.<span class="property">host</span> = <span class="variable constant_">PROXY_HOSTNAME</span>;</span><br><span class="line">      url.<span class="property">protocol</span> = <span class="variable constant_">PROXY_PROTOCOL</span>;</span><br><span class="line">      <span class="keyword">const</span> newRequest = <span class="title function_">createNewRequest</span>(</span><br><span class="line">        request,</span><br><span class="line">        url,</span><br><span class="line">        <span class="variable constant_">PROXY_HOSTNAME</span>,</span><br><span class="line">        originHostname</span><br><span class="line">      );</span><br><span class="line">      <span class="keyword">const</span> originalResponse = <span class="keyword">await</span> <span class="title function_">fetch</span>(newRequest);</span><br><span class="line">      <span class="keyword">const</span> newResponseHeaders = <span class="title function_">setResponseHeaders</span>(</span><br><span class="line">        originalResponse,</span><br><span class="line">        <span class="variable constant_">PROXY_HOSTNAME</span>,</span><br><span class="line">        originHostname,</span><br><span class="line">        <span class="variable constant_">DEBUG</span></span><br><span class="line">      );</span><br><span class="line">      <span class="keyword">const</span> contentType = newResponseHeaders.<span class="title function_">get</span>(<span class="string">&quot;content-type&quot;</span>) || <span class="string">&quot;&quot;</span>;</span><br><span class="line">      <span class="keyword">let</span> body;</span><br><span class="line">      <span class="keyword">if</span> (contentType.<span class="title function_">includes</span>(<span class="string">&quot;text/&quot;</span>)) &#123;</span><br><span class="line">        body = <span class="keyword">await</span> <span class="title function_">replaceResponseText</span>(</span><br><span class="line">          originalResponse,</span><br><span class="line">          <span class="variable constant_">PROXY_HOSTNAME</span>,</span><br><span class="line">          <span class="variable constant_">PATHNAME_REGEX</span>,</span><br><span class="line">          originHostname</span><br><span class="line">        );</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        body = originalResponse.<span class="property">body</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(body, &#123;</span><br><span class="line">        <span class="attr">status</span>: originalResponse.<span class="property">status</span>,</span><br><span class="line">        <span class="attr">headers</span>: newResponseHeaders,</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (error) &#123;</span><br><span class="line">      <span class="title function_">logError</span>(request, <span class="string">`Fetch error: <span class="subst">$&#123;error.message&#125;</span>`</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(<span class="string">&quot;Internal Server Error&quot;</span>, &#123; <span class="attr">status</span>: <span class="number">500</span> &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h1><p>docker的主要概念是镜像和容器，镜像和容器的关系就好像编程世界的类(class)和实例(instance)</p><ul><li>镜像：可以简单理解成操作系统的安装包。通过镜像可以在docker中示例化出多个容器，就好像电脑上可以装多个系统一样</li><li>容器：通过镜像实例化出来的，一个镜像可以实例化出多个容器。就好像windows的操作系统安装包镜像可以装到多个电脑上一样。</li></ul><h2 id="简单工作流"><a href="#简单工作流" class="headerlink" title="简单工作流"></a>简单工作流</h2><p>从dockerhub上拉取基础镜像，实例化出容器后，在容器内安装各种依赖和工具，然后将运行中的容器打包保存成新的镜像，最后通过docker run实例化新镜像成一个服务</p><h3 id="①-拉取镜像"><a href="#①-拉取镜像" class="headerlink" title="① 拉取镜像"></a>① 拉取镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull centos:8.4.2105  <span class="comment"># 从dockerhub拉取centos镜像保存到本地（版本为8.4.2105）</span></span><br><span class="line">docker image <span class="built_in">ls</span>  <span class="comment"># 查看本地已有的镜像</span></span><br></pre></td></tr></table></figure><h3 id="②-实例化并安装各种依赖和工具"><a href="#②-实例化并安装各种依赖和工具" class="headerlink" title="② 实例化并安装各种依赖和工具"></a>② 实例化并安装各种依赖和工具</h3><ol><li>将镜像实例化成容器</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">docker run -it \</span><br><span class="line">  -v /root/.superset:/root/.superset \</span><br><span class="line">  -e TZ=Asia/Shanghai \</span><br><span class="line">  -p 9999:9999 \</span><br><span class="line">  centos:8.4.2105 \</span><br><span class="line">  bash</span><br><span class="line"><span class="comment"># docker run: 将镜像实例化成容器的命令</span></span><br><span class="line"><span class="comment"># -it: -i和-t的常用连写，通常用于以交互模式运行容器，允许用户与容器内的进程进行交互</span></span><br><span class="line"><span class="comment">#      -i是--interactive，作用是保持标准输入（stdin）打开，即使没有连接到终端</span></span><br><span class="line"><span class="comment">#      -t是--tty，作用是为容器分配一个伪终端（pseudo-TTY）</span></span><br><span class="line"><span class="comment"># centos:8.4.2105：镜像名</span></span><br><span class="line"><span class="comment"># bash：启动容器后执行的命令，-it常和bash一起使用。也可以是其他任意命令</span></span><br><span class="line"><span class="comment"># -v：将本地的路径映射到容器内的路径，常用于持久化容器内的数据（因为容器一旦退出或重启，里面产生的数据都不会保存，因为要重新从镜像实例化出一个容器，就跟电脑重装系统一样）</span></span><br><span class="line"><span class="comment"># -p：如果容器内部署了对外服务，则需要分配端口，因此将本地的9999端口映射到容器内的9999端口。一旦映射绑定后，所有内网和公网来访问本机9999的请求，都被转发到容器内的9999端口</span></span><br></pre></td></tr></table></figure><ol start="2"><li>进入容器后就跟普通的centos终端一样，安装各种依赖和工具。如superset</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 容器内执行</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 yum 国内源</span></span><br><span class="line"><span class="built_in">cd</span> /etc/yum.repos.d/</span><br><span class="line"><span class="built_in">mkdir</span> backup &amp;&amp; <span class="built_in">mv</span> *repo backup/</span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo</span><br><span class="line">sed -i -e<span class="string">&quot;s|mirrors.cloud.aliyuncs.com|mirrors.aliyun.com|g &quot;</span> /etc/yum.repos.d/CentOS-*</span><br><span class="line">sed -i -e <span class="string">&quot;s|releasever|releasever-stream|g&quot;</span> /etc/yum.repos.d/CentOS-*</span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 miniconda</span></span><br><span class="line"><span class="built_in">mkdir</span> -p ~/.conda</span><br><span class="line">curl -o ~/.conda/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">bash ~/.conda/miniconda.sh -b -u -p ~/.conda &amp;&amp; <span class="built_in">rm</span> -f ~/.conda/miniconda.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活并初始化 miniconda</span></span><br><span class="line"><span class="built_in">source</span> ~/.conda/bin/activate &amp;&amp; conda init --all &amp;&amp; <span class="built_in">source</span> ~/.bashrc</span><br><span class="line">pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple  <span class="comment"># 全局设置清华源</span></span><br><span class="line">pip config <span class="built_in">set</span> global.index-url https://mirrors.aliyun.com/pypi/simple  <span class="comment"># 全局设置阿里源</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># conda安装 superset 虚拟环境</span></span><br><span class="line">dnf install -y gcc gcc-c++ libffi-devel python3-devel python3-pip python3-wheel openssl-devel cyrus-sasl-devel openldap-devel</span><br><span class="line"><span class="comment">#yum install cyrus-sasl-plain  cyrus-sasl-devel  cyrus-sasl-gssapi  # 非必须：添加hive连接时报错sasl相关错误时需要</span></span><br><span class="line">conda create -y -n py39superset python=3.9</span><br><span class="line">conda activate py39superset</span><br><span class="line">pip install --upgrade pip -i https://mirrors.aliyun.com/pypi/simple</span><br><span class="line">pip install apache-superset  -i https://mirrors.aliyun.com/pypi/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 superset 应用</span></span><br><span class="line"><span class="built_in">export</span> SUPERSET_SECRET_KEY=<span class="string">&quot;oh-my-recommend&quot;</span> &amp;&amp; <span class="built_in">export</span> FLASK_APP=<span class="string">&quot;superset&quot;</span></span><br><span class="line">superset db upgrade</span><br><span class="line">superset fab create-admin --username admin --firstname admin --lastname admin --email zhoutao@newlang.cn --password ohmygod</span><br><span class="line">superset init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 改成中文界面</span></span><br><span class="line">sed -i <span class="string">&#x27;s/BABEL_DEFAULT_LOCALE = &quot;en&quot;/BABEL_DEFAULT_LOCALE = &quot;zh&quot;/&#x27;</span> <span class="variable">$CONDA_PREFIX</span>/lib/python3.9/site-packages/superset/config.py</span><br><span class="line">sed -i <span class="string">&#x27;s/LANGUAGES = &#123;&#125;/LANGUAGES = &#123;&quot;zh&quot;: &#123;&quot;flag&quot;: &quot;cn&quot;, &quot;name&quot;: &quot;简体中文&quot;&#125;, &quot;en&quot;: &#123;&quot;flag&quot;: &quot;us&quot;, &quot;name&quot;: &quot;English&quot;&#125;&#125;/&#x27;</span> <span class="variable">$CONDA_PREFIX</span>/lib/python3.9/site-packages/superset/config.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装依赖包支持 hive连接</span></span><br><span class="line">pip install pyhive sasl thrift thrift-sasl pyhs2 -i https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 superset web应用</span></span><br><span class="line">SUPERSET_SECRET_KEY=<span class="string">&quot;oh-my-recommend&quot;</span> FLASK_APP=superset superset run -h <span class="string">&quot;0.0.0.0&quot;</span> -p 9999 --with-threads --reload --debugger</span><br></pre></td></tr></table></figure><ol start="3"><li>安装并测试完后，记得删除容器内的各种临时数据和缓存，减小后续打包的新镜像体积</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 容器内执行：清理临时数据和缓存</span></span><br><span class="line">yum clean all &amp;&amp; dnf clean all &amp;&amp; conda clean -y --all &amp;&amp; pip cache purge</span><br><span class="line"><span class="built_in">rm</span> -rf /tmp/* /var/tmp/* /var/log/*/*  ~/.cache/*</span><br></pre></td></tr></table></figure><h3 id="③-将运行中的容器打包保存成新的镜像"><a href="#③-将运行中的容器打包保存成新的镜像" class="headerlink" title="③ 将运行中的容器打包保存成新的镜像"></a>③ 将运行中的容器打包保存成新的镜像</h3><p>新开一个本地终端，按需执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将运行中的容器打包保存成新的镜像</span></span><br><span class="line">docker container <span class="built_in">ls</span>  <span class="comment"># 查看运行中的容器，找到目标容器的container_id</span></span><br><span class="line">docker commit &lt;container_id&gt;  &lt;新镜像名&gt;:&lt;版本号&gt;  <span class="comment"># 将运行中的容器打包保存成新的镜像</span></span><br><span class="line">docker image <span class="built_in">ls</span>  <span class="comment"># 查看新镜像信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果打包不满意（如忘记清理容器内缓存导致镜像体积太大了），可以删掉重来</span></span><br><span class="line">docker rmi &lt;新镜像名&gt;:&lt;版本号&gt;  <span class="comment"># 删除新镜像</span></span><br><span class="line">docker image prune -a  <span class="comment"># 清理已经没有容器依赖的层数据</span></span><br></pre></td></tr></table></figure><p>对新镜像满意后，可exit退出释放容器</p><h3 id="④-实例化新镜像成一个服务"><a href="#④-实例化新镜像成一个服务" class="headerlink" title="④ 实例化新镜像成一个服务"></a>④ 实例化新镜像成一个服务</h3><p>如superset web服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name superset4 \</span><br><span class="line">  --restart unless-stopped \</span><br><span class="line">  --cpus=<span class="string">&#x27;4.0&#x27;</span> --memory=<span class="string">&#x27;4g&#x27;</span> \ </span><br><span class="line">  --network=host \</span><br><span class="line">  -v /root/.superset:/root/.superset \</span><br><span class="line">  running_superset4:20250120 \</span><br><span class="line">  bash -c <span class="string">&#x27;source ~/.bashrc &amp;&amp; conda activate py39superset &amp;&amp; SUPERSET_SECRET_KEY=&quot;oh-my-recommend&quot; FLASK_APP=superset superset run -h &quot;0.0.0.0&quot; -p 9999 --with-threads --reload --debugger&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="镜像制作和推送"><a href="#镜像制作和推送" class="headerlink" title="镜像制作和推送"></a>镜像制作和推送</h2><p>通过 Dockerfile 制作镜像，并将新镜像推送到 dockerhub 云端</p><ol><li>拉取基础镜像，并将yum的源修改为国内阿里源，打包成新镜像。Dockerfile如下</li></ol><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.4</span>.<span class="number">2105</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">cd</span> /etc/yum.repos.d/ &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">mkdir</span> backup &amp;&amp; <span class="built_in">mv</span> *repo backup/ &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i -e<span class="string">&quot;s|mirrors.cloud.aliyuncs.com|mirrors.aliyun.com|g &quot;</span> /etc/yum.repos.d/CentOS-* &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    sed -i -e <span class="string">&quot;s|releasever|releasever-stream|g&quot;</span> /etc/yum.repos.d/CentOS-* &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    yum clean all &amp;&amp; dnf clean all &amp;&amp; <span class="built_in">rm</span> -rf /var/cache/yum/* &amp;&amp; \</span></span><br><span class="line"><span class="language-bash">    <span class="built_in">rm</span> -rf /tmp/* /var/tmp/* /var/log/*/*  ~/.cache/*</span></span><br></pre></td></tr></table></figure><ol start="2"><li>执行命令构建新镜像 <code>docker build -t centos:latest ./</code></li><li>将新镜像推送到 dockerhub</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">myProxyHost=<span class="string">&quot;&quot;</span>  <span class="comment"># 反代地址(若有填上，如docker.zzftt.xxx.com/)</span></span><br><span class="line">myDockerHubUserName=<span class="string">&quot;tonyzzftt&quot;</span></span><br><span class="line">docker login -u <span class="variable">$&#123;myDockerHubUserName&#125;</span>  --password-stdin <span class="variable">$&#123;myProxyHost&#125;</span></span><br><span class="line">docker tag centos:latest <span class="variable">$&#123;myProxyHost&#125;</span><span class="variable">$&#123;myDockerHubUserName&#125;</span>/centos:latest</span><br><span class="line">docker push <span class="variable">$&#123;myProxyHost&#125;</span><span class="variable">$&#123;myDockerHubUserName&#125;</span>/centos:latest</span><br><span class="line">docker rmi <span class="variable">$&#123;myProxyHost&#125;</span><span class="variable">$&#123;myDockerHubUserName&#125;</span>/centos:latest</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://developer.aliyun.com/article/1618108">Centos安装docker（linux安装docker）——超详细小白可操作手把手教程，包好用！！！-阿里云开发者社区</a></li><li><a href="https://www.cnblogs.com/Julien1021/p/16255403.html">🎋CentOS 8 更换yum国内源 - 林清|Julien - 博客园</a></li><li><a href="https://www.bilibili.com/video/BV18utReYE3D/">【Cloudflare】#2 自建Docker镜像代理加速 补充_哔哩哔哩_bilibili</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> cloudflare </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用CNCLIP模型做内容理解</title>
      <link href="/p/%E7%94%A8CNCLIP%E6%A8%A1%E5%9E%8B%E5%81%9A%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3/"/>
      <url>/p/%E7%94%A8CNCLIP%E6%A8%A1%E5%9E%8B%E5%81%9A%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="安装CNCLIP"><a href="#安装CNCLIP" class="headerlink" title="安装CNCLIP"></a>安装CNCLIP</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create <span class="literal">-y</span> <span class="literal">-n</span> py39cnclip python=<span class="number">3.9</span></span><br><span class="line">conda activate py39cnclip</span><br><span class="line"></span><br><span class="line">pip install <span class="literal">-r</span> https://raw.githubusercontent.com/OFA<span class="literal">-Sys</span>/Chinese<span class="literal">-CLIP</span>/refs/heads/master/requirements.txt  <span class="comment"># 代理 https://ghproxy.cn/...</span></span><br><span class="line">pip install cn_clip</span><br></pre></td></tr></table></figure><h1 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> cn_clip.clip <span class="keyword">import</span> load_from_name, available_models</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Available models:&quot;</span>, available_models())   <span class="comment"># Available models: [&#x27;ViT-B-16&#x27;, &#x27;ViT-L-14&#x27;, &#x27;ViT-L-14-336&#x27;, &#x27;ViT-H-14&#x27;, &#x27;RN50&#x27;]</span></span><br><span class="line">model, preprocess = load_from_name(<span class="string">&quot;ViT-B-16&quot;</span>, device=<span class="string">&quot;cpu&quot;</span>, download_root=<span class="string">&#x27;./&#x27;</span>)  <span class="comment"># 下载指定模型到当前目录./</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="应用模型"><a href="#应用模型" class="headerlink" title="应用模型"></a>应用模型</h1><h2 id="获取embedding并计算相似度"><a href="#获取embedding并计算相似度" class="headerlink" title="获取embedding并计算相似度"></a>获取embedding并计算相似度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn_clip.clip <span class="keyword">as</span> clip</span><br><span class="line"><span class="keyword">from</span> cn_clip.clip <span class="keyword">import</span> load_from_name, available_models</span><br><span class="line"></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model, preprocess = load_from_name(<span class="string">&quot;ViT-B-16&quot;</span>, device=device, download_root=<span class="string">&#x27;./&#x27;</span>)  <span class="comment"># 若./目录已有对应模型文件，则直接本地加载</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">image_url = <span class="string">&#x27;https://ghproxy.cn/https://raw.githubusercontent.com/OFA-Sys/Chinese-CLIP/refs/heads/master/examples/pokemon.jpeg&#x27;</span></span><br><span class="line">image = preprocess(Image.<span class="built_in">open</span>(image_url)).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">text = clip.tokenize([<span class="string">&quot;杰尼龟&quot;</span>, <span class="string">&quot;妙蛙种子&quot;</span>, <span class="string">&quot;小火龙&quot;</span>, <span class="string">&quot;皮卡丘&quot;</span>]).to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    image_features = model.encode_image(image)</span><br><span class="line">    text_features = model.encode_text(text)</span><br><span class="line">    <span class="comment"># 对特征进行归一化，请使用归一化后的图文特征用于下游任务</span></span><br><span class="line">    image_features /= image_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) </span><br><span class="line">    text_features /= text_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)  </span><br><span class="line"></span><br><span class="line">    logits_per_image, logits_per_text = model.get_similarity(image, text)</span><br><span class="line">    probs = logits_per_image.softmax(dim=-<span class="number">1</span>).cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Label probs:&quot;</span>, probs)  <span class="comment"># [[1.268734e-03 5.436878e-02 6.795761e-04 9.436829e-01]]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">dir_path = <span class="string">&#x27;Downloads/test_batch_image_dl&#x27;</span></span><br><span class="line">file_list = os.listdir(dir_path)</span><br><span class="line">file_fullpath_list = [os.path.join(dir_path, x) <span class="keyword">for</span> x <span class="keyword">in</span> file_list]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_one_image_feature</span>(<span class="params">image_url</span>):</span><br><span class="line">    image = preprocess(Image.<span class="built_in">open</span>(image_url)).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        image_features = model.encode_image(image)</span><br><span class="line">        image_features /= image_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> image_features  <span class="comment"># shape=[1, 512]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_batch_image_feature</span>(<span class="params">image_url_list, batch_size=<span class="number">16</span></span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(image_url_list) &gt; <span class="number">0</span>, <span class="string">&#x27;image_url_list不能为空&#x27;</span></span><br><span class="line"></span><br><span class="line">    image_features = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(image_url_list), batch_size):</span><br><span class="line">        images = torch.concat([preprocess(Image.<span class="built_in">open</span>(image_url)).unsqueeze(<span class="number">0</span>) <span class="keyword">for</span> image_url <span class="keyword">in</span> image_url_list[i:(i+batch_size)]]).to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            image_features.append(model.encode_image(images))</span><br><span class="line">    image_features = torch.concat(image_features) <span class="keyword">if</span> <span class="built_in">len</span>(image_features)&gt;<span class="number">1</span> <span class="keyword">else</span> image_features[<span class="number">0</span>]</span><br><span class="line">    image_features /= image_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> image_features  <span class="comment"># shape=[len(image_url_list), 512]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    tmp_f = get_one_image_feature(file_fullpath_list[i])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_batch_text_feature</span>(<span class="params">text_list</span>):</span><br><span class="line">    text = clip.tokenize(text_list).to(device)</span><br><span class="line">    text_features = model.encode_text(text)</span><br><span class="line">    text_features /= text_features.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> text_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_text_feature</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> get_batch_text_feature([text])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/OFA-Sys/Chinese-CLIP">OFA-Sys&#x2F;Chinese-CLIP: Chinese version of CLIP which achieves Chinese cross-modal retrieval and representation generation.</a></li><li></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Python与Jupyter的常用代码片段</title>
      <link href="/p/Python%E4%B8%8EJupyter%E7%9A%84%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"/>
      <url>/p/Python%E4%B8%8EJupyter%E7%9A%84%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="jupyter内核"><a href="#jupyter内核" class="headerlink" title="jupyter内核"></a>jupyter内核</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py390 python=3.9.0</span><br><span class="line">pip install ipykernel</span><br><span class="line">python -m ipykernel install --user --name=py390 --display-name py390</span><br><span class="line">jupyter kernelspec list</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一、安装中文字体并刷新缓存</span></span><br><span class="line">wget https://us-logger1.oss-cn-beijing.aliyuncs.com/SimHei.ttf</span><br><span class="line">sudo mkdir -p /usr/share/fonts/chinese/ &amp;&amp; sudo mv SimHei.ttf /usr/share/fonts/chinese/</span><br><span class="line">fc-list :lang=zh   # 查看是否已有中文字体了</span><br><span class="line">fc-cache  # 更新字体缓存</span><br><span class="line">rm -rf ~/.cache/matplotlib  # 删除缓存目录</span><br><span class="line">rm -rf ~/.matplotlib/*.cache  # 如果有字体，绘图还是显示小方块，则需要强力删除</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">二、手动重启python或jupyter notebook的内核</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">三、永久修改配置文件 或 临时python设置</span></span><br><span class="line">echo `python -c &quot;import matplotlib; print(matplotlib.matplotlib_fname()) &quot;`  # 获取matplotlibrc配置文件路径</span><br><span class="line">vim  `python -c &quot;import matplotlib; print(matplotlib.matplotlib_fname()) &quot;`  # 修改配置文件</span><br><span class="line">    # font.sans-serif: SimHei, &lt;...原来的字体列表&gt;    # 在原来的字体列表前面加上SimHei</span><br><span class="line">    # axes.unicode_minus: False   # 原来是True的改成False即可</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时修改配置，仅当前会话生效</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span>  <span class="comment"># 设置字体为支持中文的字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决负号显示问题</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Superset数据看板平台搭建</title>
      <link href="/p/Superset%E6%95%B0%E6%8D%AE%E7%9C%8B%E6%9D%BF%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/"/>
      <url>/p/Superset%E6%95%B0%E6%8D%AE%E7%9C%8B%E6%9D%BF%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>Superset 是一个现代数据探索和数据可视化平台。Superset 可以替代或增强许多团队的专有商业智能工具。Superset 与各种数据源很好地集成。</p><p>Superset 提供：</p><ul><li>用于快速构建图表的<strong>无代码界面</strong></li><li>一个强大的、基于 Web 的  <strong>SQL 编辑器</strong> ，用于高级查询</li><li>用于快速定义自定义维度和指标的<strong>轻量级语义层</strong></li><li>对<strong>几乎任何 SQL</strong> 数据库或数据引擎的开箱即用支持</li><li>各种<strong>精美的可视化</strong>效果来展示您的数据，从简单的条形图到地理空间可视化效果</li><li>轻量级、可配置的 <strong>缓存层</strong> ，有助于减轻数据库负载</li><li>高度可扩展的<strong>安全角色和身份验证</strong>选项</li><li>用于编程自定义的 <strong>API</strong></li><li>专为扩展而设计的<strong>云原生架构</strong></li></ul><h1 id="在Centos上用Conda安装"><a href="#在Centos上用Conda安装" class="headerlink" title="在Centos上用Conda安装"></a>在Centos上用Conda安装</h1><ol><li>系统基础依赖安装<ol><li>旧版的centos上：<code>sudo yum install gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel cyrus-sasl-devel openldap-devel</code></li><li>较为新版的centos上：<code>sudo dnf install gcc gcc-c++ libffi-devel python3-devel python3-pip python3-wheel openssl-devel cyrus-sasl-devel openldap-devel</code><ol><li>如果后续看到有报错sasl的错误，再安装 <code>yum install cyrus-sasl-plain  cyrus-sasl-devel  cyrus-sasl-gssapi  # 非必须：添加hive连接时报错sasl相关错误时需要</code></li></ol></li></ol></li><li>conda安装python依赖包<ol><li><code>conda create -n py39superset python=3.9</code>   # 最低需要3.9</li><li><code>conda activate py39superset</code></li><li><code>pip install --upgrade pip</code>   # 不能太老版本的pip</li><li><code>pip install apache-superset  -i https://mirrors.aliyun.com/pypi/simple</code></li><li><code>export SUPERSET_SECRET_KEY=&quot;oh-my-recommend&quot; &amp;&amp; export FLASK_APP=&quot;superset&quot;</code>  # 配置环境变量</li><li><code>superset db upgrade</code>   # 初始化db</li><li><code>superset fab create-admin</code>   # Create an admin user in your metadata database (use <code>admin</code> as username to be able to load the examples)</li><li><code>superset load_examples</code>  # (可选) 从网络上加载个demo数据集用于play（大概率会遭遇网络问题，建议跳过本步骤）</li><li><code>superset init</code>  # 创建默认角色和权限</li><li><code>pip install pyhive sasl thrift thrift-sasl pyhs2 -i https://mirrors.aliyun.com/pypi/simple/</code>  # 连接hive需要的依赖包</li></ol></li><li>在开发环境启动：<ol><li><code>SUPERSET_SECRET_KEY=&quot;oh-my-recommend&quot; FLASK_APP=superset superset run -h &#39;0.0.0.0&#39; -p 9999 --with-threads --reload --debugger</code>   # To start a development web server on port 9999, use -p to bind to another port （服务器上记得开放9999端口）</li><li>然后用ip:9999在浏览器访问即可。本地的话ip可以用localhost，服务器上可用公网ip访问（<code>curl cip.cc</code>可获取到公网IP）</li></ol></li></ol><h1 id="界面改成中文"><a href="#界面改成中文" class="headerlink" title="界面改成中文"></a>界面改成中文</h1><ol><li>修改 <code>~/.conda/envs/py39superset/lib/python3.9/site-packages/superset/config.py</code>文件<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到 BABEL_DEFAULT_LOCALE 将其改为</span></span><br><span class="line">BABEL_DEFAULT_LOCALE = <span class="string">&quot;zh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到 LANGUAGES = &#123;&#125; 将其改为</span></span><br><span class="line">LANGUAGES = &#123;</span><br><span class="line">    <span class="string">&quot;en&quot;</span>: &#123;<span class="string">&quot;flag&quot;</span>: <span class="string">&quot;us&quot;</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;English&quot;</span>&#125;,</span><br><span class="line">    <span class="string">&quot;zh&quot;</span>: &#123;<span class="string">&quot;flag&quot;</span>: <span class="string">&quot;cn&quot;</span>, <span class="string">&quot;name&quot;</span>: <span class="string">&quot;简体中文&quot;</span>&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>重启服务生效</li></ol><h1 id="SuperSet连接Hive数据库"><a href="#SuperSet连接Hive数据库" class="headerlink" title="SuperSet连接Hive数据库"></a>SuperSet连接Hive数据库</h1><ol><li>点击右上角 <code>Settings</code> -&gt; <code>数据库连接</code> -&gt; <code>+DATABASE</code> -&gt; <code>Apache Hive</code></li><li>在 <code>SQLAlchemy URI</code>中输入 <code>hive://hive@localhost:10000/default</code>，点击 <code>TEST CONNECTION</code>测试连接是否成功</li><li>在 <code>ADVANCED</code> 选项卡中，在 <code>Other</code>的 <code>Engine Parameters</code>中输入 <code>&#123;&quot;connect_args&quot;:&#123;&quot;configuration&quot;:&#123;&quot;hive.execution.engine&quot;:&quot;tez&quot;&#125;&#125;&#125;</code>以启用tez引擎而非默认的MR引擎</li><li>最后点击 <code>CONNECT</code> 完成即可（可能弹出报错，但忽略并刷新网页即可）</li></ol><h1 id="SuperSet连接Spark-SQL"><a href="#SuperSet连接Spark-SQL" class="headerlink" title="SuperSet连接Spark-SQL"></a>SuperSet连接Spark-SQL</h1><ol><li>点击右上角 <code>Settings</code> -&gt; <code>数据库连接</code> -&gt; <code>+DATABASE</code> -&gt; <code>Apache Spark SQL</code></li><li>在 <code>SQLAlchemy URI</code>中输入 <code>hive://hive@localhost:10001/default</code>(默认是10000和hiveserver冲突)，点击 <code>TEST CONNECTION</code>测试连接是否成功</li><li>最后点击 <code>CONNECT</code> 完成即可</li><li>(可选)解决获取不到表名的问题：手动改pyhive的代码，将 <code>/root/miniconda3/envs/py39superset/lib/python3.9/site-packages/pyhive/sqlalchemy_hive.py</code> 中的 <code>get_table_names</code> 函数中 <code>return [row[0] for row in connection.execute(text(query))]</code> 的改为 <code>return [row[0] if len(row)!=3 else row[1] for row in connection.execute(text(query))]</code></li></ol><h1 id="创建图表和看板"><a href="#创建图表和看板" class="headerlink" title="创建图表和看板"></a>创建图表和看板</h1><ol><li>点击 <code>数据集</code> TAB，点击 <code>+DATASET</code> 按钮</li><li>选择 <code>Database</code> -&gt; <code>Schema</code> -&gt; <code>Table</code> -&gt; <code>Create dataset and create chart</code>，完成将Hive的一张表映射为这里的DataSet</li><li>选择 <code>Line Chart</code>为例<ol><li>DATA 子选项卡<ol><li>X-AXIS：选择做为x轴的列。常用的如：日期</li><li>METRICS：选择做为y轴的指标（可多选）。如：次留，首日LTV等</li><li>DIMENSIONS：选择做为分组对比的列。如：分实验组看多天的次留指标趋势，这里的实验组就是DIMENSIONS</li><li>FILTERS：等效于SQL中的WHERE&#x2F;HAVING语句，过滤一些不要的数据。如：按天分区筛选</li><li>其他：大部分时候保持默认即可</li></ol></li><li>CUSTOMIZE 子选项卡<ol><li>X Axis：配置x轴标题以及标题离刻度的距离。中文建议距离30而非默认的15</li><li>Y Axis：配置y轴标题以及标题离刻度的距离。中文建议默认的15即可，Y Axis Title Position建议选Top而非默认的Left</li><li>SHOW VALUE：显示每个点的值，适合少量数据或条形图</li><li>MARKER：加粗显示每个点</li><li>DATA ZOOM：显示拖动条，可拖动X轴的刻度范围，如日期可拖动选择任意一段时间内的数据显示</li><li>Y  AXIS  FORMAT：可选择百分数显示</li><li>TRUNCATE Y AXIS：截断Y轴的空白区域</li></ol></li></ol></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://github.com/apache/superset">apache&#x2F;superset：Apache Superset 是一个数据可视化和数据探索平台</a></li><li><a href="https://superset.apache.org/docs/installation/pypi">PyPI | Superset</a></li><li><a href="https://blog.csdn.net/xwd127429/article/details/118995202">Superset连接Spark-SQL_superset连spark-CSDN博客</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> DashBoard </tag>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive和Spark常用代码片段</title>
      <link href="/p/Hive%E5%92%8CSpark%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/"/>
      <url>/p/Hive%E5%92%8CSpark%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><ul><li>日期类</li></ul><table><thead><tr><th>功能</th><th>示例代码</th><th>备注</th></tr></thead><tbody><tr><td>日期有无横杠转换</td><td>date_format(from_unixtime(unix_timestamp(‘20240101’, ‘yyyyMMdd’)), ‘yyyy-MM-dd’)</td><td>输出”2024-01-01”</td></tr><tr><td>日期加减</td><td>date_format(date_add(from_unixtime(unix_timestamp(‘20240101’, ‘yyyyMMdd’)), 7), ‘yyyyMMdd’)</td><td>输出”2024-01-08”</td></tr><tr><td>日期差</td><td>datediff(from_unixtime(unix_timestamp(‘20240105’, ‘yyyyMMdd’)), from_unixtime(unix_timestamp(‘20240101’, ‘yyyyMMdd’)))</td><td>输出 4</td></tr></tbody></table><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time, datetime</span><br><span class="line"><span class="keyword">from</span> spark_util <span class="keyword">import</span> spark_start</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;spark&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">globals</span>():</span><br><span class="line">    spark = spark_start(<span class="string">&#x27;data_explore_zt&#x27;</span>, executor_core=<span class="number">2</span>)</span><br><span class="line">    spark.sparkContext.setLogLevel(<span class="string">&quot;ERROR&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">sdf, n=<span class="literal">None</span>, truncate=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">    pd.options.display.max_columns = <span class="number">100</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> truncate:</span><br><span class="line">        pd.options.display.max_colwidth = <span class="number">999</span></span><br><span class="line">    n = n <span class="keyword">or</span> (<span class="number">5</span> <span class="keyword">if</span> <span class="built_in">len</span>(sdf.columns) &gt; <span class="number">10</span> <span class="keyword">else</span> <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> display(pd.DataFrame([x.asDict() <span class="keyword">for</span> x <span class="keyword">in</span> sdf.take(n)]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_date</span>(<span class="params">n=-<span class="number">1</span>, base_date=<span class="literal">None</span>, base_date_FMT=<span class="literal">None</span>, FMT=<span class="string">&#x27;%Y%m%d&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">if</span> base_date <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> pytz</span><br><span class="line">            base_datetime = datetime.datetime.now(pytz.timezone(<span class="string">&#x27;Asia/Shanghai&#x27;</span>))</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            base_datetime = datetime.datetime.now()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        base_datetime = datetime.datetime.strptime(base_date, base_date_FMT <span class="keyword">or</span> FMT)</span><br><span class="line">    <span class="keyword">return</span> datetime.datetime.strftime(base_datetime + datetime.timedelta(n), FMT)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">date_range</span>(<span class="params">start, end, end_include=<span class="literal">False</span>, step=<span class="number">1</span>, FMT=<span class="string">&quot;%Y%m%d&quot;</span></span>):</span><br><span class="line">    strptime, strftime = datetime.datetime.strptime, datetime.datetime.strftime</span><br><span class="line">    days = (strptime(end, FMT) - strptime(start, FMT)).days</span><br><span class="line">    days = days + <span class="built_in">int</span>(step/<span class="built_in">abs</span>(step)) <span class="keyword">if</span> end_include <span class="keyword">else</span> days  <span class="comment"># +1 OR -1</span></span><br><span class="line">    <span class="keyword">return</span> [strftime(strptime(start, FMT) + datetime.timedelta(i), FMT) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, days, step)]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h1><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;spark.executor.instances&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;spark.executor.memory&quot;</span><span class="punctuation">:</span> <span class="string">&quot;3g&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;spark.executor.cores&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VSCode常用插件</title>
      <link href="/p/VSCode%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/"/>
      <url>/p/VSCode%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><ul><li><code>Chinese (Simplified) (简体中文) Language Pack for Visual Studio Code</code>：将系统变为中文界面</li></ul><h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><ul><li><code>Jupyter</code>：查看和编辑ipynb文件；还可连接远程的jupyter内核在本地开发</li></ul><h1 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h1><ul><li><code>Office Viewer(Markdown Editor)</code>：类似typora的所见即所得的markdown编辑插件</li></ul><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ul><li>“因为在此系统上禁止运行脚本”解决办法：管理员权限运行power shell：<code>set-ExecutionPolicy RemoteSigned</code>，之后选择“是(Y)”</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VSCode </tag>
            
            <tag> 插件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客搭建02-AnZhiYu主题配置</title>
      <link href="/p/HexoBlog02/"/>
      <url>/p/HexoBlog02/</url>
      
        <content type="html"><![CDATA[<h1 id="一、安装主题anzhiyu"><a href="#一、安装主题anzhiyu" class="headerlink" title="一、安装主题anzhiyu"></a>一、安装主题anzhiyu</h1><p>按下面步骤安装好后，执行hexo cl; hexo s命令，看到最后一行输出为 <code>running at http://localhost:4000</code> 即可在浏览器打开链接，效果如下：<br><img src="/static/img/714d04854370cfbfd64c6.jpg" alt="anzhiyu主题首页效果"></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装主题</span></span><br><span class="line"><span class="string">git</span> <span class="string">clone</span> <span class="string">-b</span> <span class="string">main</span> <span class="string">https://github.com/anzhiyu-c/hexo-theme-anzhiyu.git</span> <span class="string">themes/anzhiyu</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 pug 和 stylus 渲染插件</span></span><br><span class="line"><span class="string">npm</span> <span class="string">install</span> <span class="string">hexo-renderer-pug</span> <span class="string">hexo-renderer-stylus</span> <span class="string">--save</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用主题</span></span><br><span class="line"><span class="string">cp</span> <span class="string">./themes/anzhiyu/_config.yml</span> <span class="string">./_config.anzhiyu.yml</span></span><br><span class="line"><span class="comment"># 在_config.yml文件里修改 &quot;theme: anzhiyu&quot;</span></span><br></pre></td></tr></table></figure><h1 id="二、首页配置"><a href="#二、首页配置" class="headerlink" title="二、首页配置"></a>二、首页配置</h1><h2 id="2-1-分类页-标签页-隧道页"><a href="#2-1-分类页-标签页-隧道页" class="headerlink" title="2.1 分类页&#x2F;标签页&#x2F;隧道页"></a>2.1 分类页&#x2F;标签页&#x2F;隧道页</h2><ol><li>修改<code>_config.anzhiyu.yml</code>配置文件：将 文章&#x2F;隧道&#x2F;分类&#x2F;标签 取消注释。这会在网站上方生成文章导航按钮（但此时点进去找不到页面） <img src="/static/img/91a36673baa66f46652d5.jpg" alt="文章/隧道/分类/标签页"></li><li>生成分类页<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 标签</span><br><span class="line">date: 2024-08-05 20:31:05</span><br><span class="line">type: &quot;tags&quot;</span><br><span class="line">comments: false</span><br><span class="line"><span class="section">top<span class="emphasis">_img: false</span></span></span><br><span class="line"><span class="emphasis"><span class="section">---</span></span></span><br></pre></td></tr></table></figure><ol><li>在 Hexo 博客根目录下打开终端，输入hexo new page tags</li><li>你会找到 source&#x2F;tags&#x2F;index.md 这个文件。修改这个文件： 记得添加 type: “tags”</li><li>访问链接 &#x2F;tags即可查看</li></ol></li><li>生成标签页<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 分类</span><br><span class="line">date: 2024-08-05 20:33:42</span><br><span class="line">type: &quot;categories&quot;</span><br><span class="line">aside: false</span><br><span class="line"><span class="section">top<span class="emphasis">_img: false</span></span></span><br><span class="line"><span class="emphasis"><span class="section">---</span></span></span><br></pre></td></tr></table></figure><ol><li>在 Hexo 博客根目录下打开终端，输入hexo new page categories</li><li>你会找到 source&#x2F;categories&#x2F;index.md 这个文件。修改这个文件： 记得添加 type: “categories”</li><li>访问链接 &#x2F;categories即可查看</li></ol></li></ol><h2 id="2-2-顶部左侧导航栏"><a href="#2-2-顶部左侧导航栏" class="headerlink" title="2.2 顶部左侧导航栏"></a>2.2 顶部左侧导航栏</h2><p>在<code>_config.anzhiyu.yml</code>文件中修改 <img src="/static/img/34626922dfe74e454708a.jpg" alt="顶部左侧导航栏效果图"></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nav:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">travelling:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">clock:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">menu:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">title:</span> <span class="string">网页</span></span><br><span class="line">      <span class="attr">item:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">博客</span></span><br><span class="line">          <span class="attr">link:</span> <span class="string">https://blog.dreamyai.fun/</span></span><br><span class="line">          <span class="attr">icon:</span> <span class="string">/img/favicon.ico</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">title:</span> <span class="string">项目</span></span><br><span class="line">      <span class="attr">item:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">临时图床</span></span><br><span class="line">          <span class="attr">link:</span> <span class="string">https://images.zzftt.cloudns.biz/</span></span><br><span class="line">          <span class="attr">icon:</span> <span class="string">https://images.zzftt.cloudns.biz/favicon.ico</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">临时互联</span></span><br><span class="line">          <span class="attr">link:</span> <span class="string">https://daili.zzftt.cloudns.biz/</span></span><br><span class="line">          <span class="attr">icon:</span> <span class="string">https://daili.zzftt.cloudns.biz/favicon.ico</span></span><br></pre></td></tr></table></figure><h2 id="2-3-点亮首页技能点"><a href="#2-3-点亮首页技能点" class="headerlink" title="2.3 点亮首页技能点"></a>2.3 点亮首页技能点</h2><ol><li>在文件中，关闭默认的peoplecanvas：<code>peoplecanvas</code> -&gt; <code>enable: false</code></li><li>创建<code>source/_data/creativity.yml</code>，输入以下内容</li><li>文字部分在主题配置文件中home_top配置项修改<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">class_name:</span> <span class="string">开启创造力</span></span><br><span class="line">  <span class="attr">creativity_list:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Python</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#fff&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2023/04/09/643293b1230f7.png</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Tensorflow</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#fff&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://ts2.cn.mm.bing.net/th?id=OSAAS.5626C07A9FB89E37617BD7C8C7363F07&amp;w=256&amp;h=256</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PyTorch</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#fff&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://pytorch.org/assets/images/logo-dark.svg</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Spark</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#fff&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://spark.apache.org/images/spark-logo.png</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Docker</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#57b6e6&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2023/04/09/643293b0f0abe.png</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Git</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#df5b40&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2023/04/09/643293b10ccdd.webp</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CSS3</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#2c51db&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2022/12/15/639aa3a5c251e.png</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">JS</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#f7cb4f&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2023/04/09/643293b121f02.png</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">HTML</span></span><br><span class="line">      <span class="attr">color:</span> <span class="string">&quot;#e9572b&quot;</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">https://bu.dusays.com/2022/12/15/639aa3a5c241c.png</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="2-4-自定义首页顶部category"><a href="#2-4-自定义首页顶部category" class="headerlink" title="2.4 自定义首页顶部category"></a>2.4 自定义首页顶部category</h2><p><img src="/static/img/8741d49c14f79e93f0654.jpg" alt="首页顶部category效果图"></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首页顶部相关配置</span></span><br><span class="line"><span class="attr">home_top:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># 开关</span></span><br><span class="line">  <span class="attr">timemode:</span> <span class="string">date</span> <span class="comment">#date/updated</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">生活明朗</span></span><br><span class="line">  <span class="attr">subTitle:</span> <span class="string">万物可爱。</span></span><br><span class="line">  <span class="attr">siteText:</span> <span class="string">blog.dreamyai.fun</span></span><br><span class="line">  <span class="attr">category:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">技术</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/categories/技术/</span></span><br><span class="line">      <span class="attr">shadow:</span> <span class="string">var(--anzhiyu-shadow-blue)</span></span><br><span class="line">      <span class="attr">class:</span> <span class="string">blue</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">anzhiyu-icon-dove</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">投资</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/categories/投资/</span></span><br><span class="line">      <span class="attr">shadow:</span> <span class="string">var(--anzhiyu-shadow-red)</span></span><br><span class="line">      <span class="attr">class:</span> <span class="string">red</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">anzhiyu-icon-fire</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">生活</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/categories/生活日常/</span></span><br><span class="line">      <span class="attr">shadow:</span> <span class="string">var(--anzhiyu-shadow-green)</span></span><br><span class="line">      <span class="attr">class:</span> <span class="string">green</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">anzhiyu-icon-book</span></span><br><span class="line">  <span class="attr">default_descr:</span> <span class="string">再怎么看我也不知道怎么描述它的啦！</span></span><br><span class="line">  <span class="attr">swiper:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">swiper_css:</span> <span class="string">https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css</span> <span class="comment">#swiper css依赖</span></span><br><span class="line">    <span class="attr">swiper_js:</span> <span class="string">https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.js</span> <span class="comment">#swiper js依赖</span></span><br><span class="line">  <span class="attr">banner:</span></span><br><span class="line">    <span class="attr">tips:</span> <span class="string">新品主题</span></span><br><span class="line">    <span class="attr">title:</span> <span class="string">Theme-AnZhiYu</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">https://bu.dusays.com/2023/05/13/645fa3cf90d70.webp</span></span><br><span class="line">    <span class="attr">link:</span> <span class="string">https://docs.anheyu.com/</span></span><br></pre></td></tr></table></figure><h2 id="2-5-右侧栏作者卡片"><a href="#2-5-右侧栏作者卡片" class="headerlink" title="2.5 右侧栏作者卡片"></a>2.5 右侧栏作者卡片</h2><ol><li>在<code>_config.anzhiyu.yml</code>文件中，开启<code>author_status</code> -&gt; <code>enable: true</code></li><li>修改 <code>author_status</code> -&gt; <code>statusImg</code>的表情成自定义喜欢的表情或图片</li><li><code>author_status</code> -&gt; <code>skills</code>后面的注释全部开启</li><li>取消注释并自定义修改描述 <code>card_author</code> -&gt; <code>description</code></li></ol><h2 id="2-6-关闭公众号卡片"><a href="#2-6-关闭公众号卡片" class="headerlink" title="2.6 关闭公众号卡片"></a>2.6 关闭公众号卡片</h2><ol><li>在<code>_config.anzhiyu.yml</code>文件中，关闭<code>card_weixin</code> -&gt; <code>enable: false</code></li></ol><h2 id="2-7-开启搜索功能"><a href="#2-7-开启搜索功能" class="headerlink" title="2.7 开启搜索功能"></a>2.7 开启搜索功能</h2><ol><li>安装插件：在博客根目录下执行下列命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure></li><li>修改_config.anzhiyu.yml配置文件：修改local_search的enable为true<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Local search</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">preload:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">CDN:</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="2-9-其他"><a href="#2-9-其他" class="headerlink" title="2.9 其他"></a>2.9 其他</h2><ol><li>点击烟火特效<ol><li>（主题配置文件）<code>fireworks</code> -&gt; <code>enable: true</code></li></ol></li><li>修改文章链接，方便推广<ol><li>（全局配置文件）<code>permalink: p/:alias/</code></li><li>所有文章都补上alias字段</li></ol></li><li>修改文章地理位置<ol><li>（主题配置文件）<code>post_copyright</code> -&gt; <code>广州</code></li></ol></li></ol><h1 id="三、功能配置"><a href="#三、功能配置" class="headerlink" title="三、功能配置"></a>三、功能配置</h1><h2 id="3-1-字数统计"><a href="#3-1-字数统计" class="headerlink" title="3.1 字数统计"></a>3.1 字数统计</h2><ol><li>安装插件 <code>npm install hexo-wordcount --save</code></li><li>修改 主题配置文件。（文章页标题下方和首页底部右侧都有字数统计）<br><img src="/static/img/e2d37f4ec12d3ee160598.jpg" alt="字数统计效果图"><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">wordcount:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">post_wordcount:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">min2read:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">total_wordcount:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="3-2-访问人数"><a href="#3-2-访问人数" class="headerlink" title="3.2 访问人数"></a>3.2 访问人数</h2><p>修改<code>_config.anzhiyu.yml</code>文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># busuanzi count for PV / UV in site</span></span><br><span class="line"><span class="comment"># 访问人数</span></span><br><span class="line"><span class="attr">busuanzi:</span></span><br><span class="line">  <span class="attr">site_uv:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">site_pv:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">page_pv:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="3-3-音乐馆"><a href="#3-3-音乐馆" class="headerlink" title="3.3 音乐馆"></a>3.3 音乐馆</h2><ol><li>执行<code>hexo new page music</code>，生成并手动修改<code>source/music/index.md</code><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 音乐馆</span><br><span class="line">date: 2024-08-06 08:41:30</span><br><span class="line">type: music</span><br><span class="line">aplayer: true</span><br><span class="line">top<span class="emphasis">_img: false</span></span><br><span class="line"><span class="emphasis">comments: false</span></span><br><span class="line"><span class="emphasis">aside: false</span></span><br><span class="line"><span class="emphasis">---</span></span><br></pre></td></tr></table></figure></li><li>新建<code>source/json/music.json</code>，此 json 为切换歌单按钮的歌单数据（自定义歌单）<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;青花瓷&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/青花瓷/青花瓷.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002eFUFm2XYZ7z_2.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/青花瓷/青花瓷.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;稻香&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/稻香/稻香.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002Neh8l0uciQZ_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/稻香/稻香.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;晴天&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/晴天/晴天.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000000MkMni19ClKG_3.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/晴天/晴天.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;七里香&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/七里香/七里香.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000003DFRzD192KKD_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/七里香/七里香.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;花海&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/花海/花海.flac&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002Neh8l0uciQZ_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/花海/花海.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;反方向的钟&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/反方向的钟/反方向的钟.flac&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000000f01724fd7TH_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/反方向的钟/反方向的钟.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;兰亭序&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/兰亭序/兰亭序.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002Neh8l0uciQZ_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/兰亭序/兰亭序.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;说好的辛福呢&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/说好的辛福呢/说好的辛福呢.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002Neh8l0uciQZ_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/说好的辛福呢/说好的幸福呢.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;等你下课 (with 杨瑞代)&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/等你下课/等你下课.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000003bSL0v4bpKAx_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.1/周杰伦/等你下课/等你下课.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我落泪情绪零碎&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/我落泪情绪零碎/我落泪情绪零碎.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000000bviBl4FjTpO_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/我落泪情绪零碎/我落泪情绪零碎.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;听妈妈的话&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/听妈妈的话/听妈妈的话.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002jLGWe16Tf1H_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.2/听妈妈的话/听妈妈的话.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;明明就&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/明明就/明明就.flac&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000003Ow85E3pnoqi_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/明明就/明明就.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我是如此相信&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/我是如此相信/我是如此相信.flac&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000001hGx1Z0so1YX_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music-jay@1.0.1/我是如此相信/我是如此相信.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;发如雪&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/发如雪/发如雪.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M0000024bjiL2aocxT_3.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/发如雪/发如雪.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;以父之名&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/以父之名/以父之名.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000000MkMni19ClKG_3.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/以父之名/以父之名.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;园游会&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/园游会/园游会.flac&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000003DFRzD192KKD_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.3/园游会/园游会.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;本草纲目&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/本草纲目/本草纲目.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000002jLGWe16Tf1H_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/本草纲目/本草纲目.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;龙卷风&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;artist&quot;</span><span class="punctuation">:</span> <span class="string">&quot;周杰伦&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/龙卷风/龙卷风.mp3&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;cover&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://y.qq.com/music/photo_new/T002R300x300M000000f01724fd7TH_1.jpg?max_age=2592000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;lrc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://npm.elemecdn.com/anzhiyu-music@1.0.4/龙卷风/龙卷风.lrc&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure></li><li>hexo 配置文件<code>_config.yml</code>中添加以下配置，注意不是主题配置文件<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># APlayer</span></span><br><span class="line"><span class="comment"># https://github.com/MoePlayer/hexo-tag-aplayer/blob/master/docs/README-zh_cn.md</span></span><br><span class="line"><span class="attr">aplayer:</span></span><br><span class="line">  <span class="attr">meting:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">asset_inject:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li>主题配置文件中开启menu中我的和音乐馆的注释，注意缩进！！！<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">文章:</span></span><br><span class="line">    <span class="string">隧道:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">icon-box-archive</span></span><br><span class="line">    <span class="string">分类:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">icon-shapes</span></span><br><span class="line">    <span class="string">标签:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">icon-tags</span></span><br><span class="line"></span><br><span class="line">  <span class="string">我的:</span></span><br><span class="line">    <span class="string">音乐馆:</span> <span class="string">/music/</span> <span class="string">||</span> <span class="string">icon-music</span></span><br><span class="line">  <span class="comment">#   追番页: /bangumis/ || icon-bilibili1</span></span><br><span class="line">  <span class="comment">#   相册集: /album/ || icon-images</span></span><br><span class="line">  <span class="comment">#   小空调: /air-conditioner/ || icon-fan</span></span><br></pre></td></tr></table></figure></li><li>修改默认歌单：将menu中音乐馆的路径修改为以下格式即可&#x2F;music&#x2F;?id&#x3D;55519285&amp;server&#x3D;netease，支持id和server参数。id 与 server 的填写请参考 <a href="https://github.com/metowolf/MetingJS">MetingJS</a></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://docs.anheyu.com/initall.html">安装主题 | 安知鱼主题</a></li><li><a href="https://docs.anheyu.com/page/tags.html">标签页配置 | 安知鱼主题</a></li><li><a href="https://docs.anheyu.com/page/classify.html">分类页配置 | 安知鱼主题</a></li><li><a href="https://docs.anheyu.com/page/music.html">音乐馆页配置 | 安知鱼主题</a></li><li><a href="https://docs.anheyu.com/advanced/#%E9%A6%96%E9%A1%B5%E6%8A%80%E8%83%BD%E7%82%B9%E9%85%8D%E7%BD%AE">首页技能点 | 全局配置</a></li><li><a href="https://docs.anheyu.com/advanced/#%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1">字数统计 | 全局配置</a></li><li><a href="https://blog.cmliussss.com/p/HexoBlogNo2/">【Hexo博客系列】No.2 美化Hexo博客，教你如何安装和美化Hexo博客 - 使用安知鱼主题进行个性化配置，涵盖安装、设置、标签页生成及本地搜索</a></li><li><a href="https://www.youtube.com/watch?v=Qss3XdMsHKM">【Hexo博客系列】No.2 美化Hexo博客，详细教程，教你如何安装和美化Hexo博客 - 使用安知鱼主题进行个性化配置，涵盖安装、设置、标签页生成及本地搜索等内容</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> github pages </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客搭建01: github pages托管和自定义域名</title>
      <link href="/p/HexoBlog01/"/>
      <url>/p/HexoBlog01/</url>
      
        <content type="html"><![CDATA[<h1 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h1><h2 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1 环境准备"></a>1.1 环境准备</h2><h3 id="①-Node-js"><a href="#①-Node-js" class="headerlink" title="① Node.js"></a>① Node.js</h3><ol><li>打开<a href="https://nodejs.org/en">Node官网</a>，下载和自己系统相配的Node的安装程序，否则会出现安装问题</li><li>下载后安装，安装的目录可以使用默认目录 <code>C:/Program Files/nodejs/</code></li><li>安装完成后，检查是否安装成功。在键盘按下 <code>win + R</code>键，输入 <code>CMD</code>，然后回车，打开CMD窗口，执行 <code>node -v</code>命令，看到版本信息，则说明安装成功 <img src="/static/img/51d420b8d3e810bc6383d.jpg" alt="CMD执行node -v"><ol><li>hexo:7.3.0 + nodejs:18.20.5</li></ol></li><li>修改npm源。npm下载各种模块，默认是从国处服务器下载，速度较慢，建议配置成华为云镜像源。打开CMD窗口，运行如下命令</li></ol><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://mirrors.huaweicloud.com/repository/npm/</span><br></pre></td></tr></table></figure><h3 id="②-安装Git"><a href="#②-安装Git" class="headerlink" title="② 安装Git"></a>② 安装Git</h3><ol><li>进入<a href="https://git-scm.com/downloads">官网</a>下载适合你当前系统的 Git（如64-bit Git For Windows Setup）</li><li>下载后傻瓜式安装Git即可，安装的目录最好使用默认目录 <code>C:/Program Files/Git</code></li><li>点击电脑左下角开始图标即可看见Git CMD、Git Bash、Git GUI<ul><li>Git CMD 是windows 命令行的指令风格</li><li>Git Bash 是linux系统的指令风格（建议使用）</li><li>Git GUI是图形化界面（新手学习不建议使用）</li></ul></li><li>打开 Git Bash，完成基础配置：用户名和邮箱</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;你的用户名&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;你的邮箱&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 此命令 检查是否配置成功。</span></span><br><span class="line">git config -l</span><br></pre></td></tr></table></figure><ol start="5"><li>执行以下命令生成ssh公钥，此公钥用于你的计算机连接Github。之后打开C盘下用户文件夹下的.ssh的文件夹(<code>C:/Users/&lt;你的用户名&gt;/.ssh/</code>)，会看到id_rsa私钥和id_rsa.pub公钥2个文件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你的邮箱&quot;</span>  <span class="comment"># 交互式，一直按回车即可</span></span><br></pre></td></tr></table></figure><ol start="6"><li>用记事本打开公钥id_rsa.pub，复制里面全部内容，然后开始在github中配置ssh密钥<ol><li>进入github，点击右上角头像 选择settings</li><li>进入设置页后选择 SSH and GPG keys，点击New SSH Key</li><li>Title 名字随便起，公钥填到Key那一栏，点击Add SSH Key保存</li></ol></li><li>测试连接，输入以下命令。第一次连接会提示Are you sure you want to continue connecting (yes&#x2F;no&#x2F;[fingerprint])?，输入yes即可。看到Successfully字样即为成功</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure><h2 id="1-2-安装Hexo"><a href="#1-2-安装Hexo" class="headerlink" title="1.2 安装Hexo"></a>1.2 安装Hexo</h2><ol><li>创建一个文件夹来保存博客源码（如：D:\Blog），在文件夹内右键鼠标，选择Open Git Bash here</li><li>在Git BASH输入如下命令安装 Hexo</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli &amp;&amp; hexo -v</span><br></pre></td></tr></table></figure><ol start="3"><li>安装完后输入hexo -v验证是否安装成功。正常显示各个依赖的版本号即为成功</li></ol><h1 id="二、本地运行博客"><a href="#二、本地运行博客" class="headerlink" title="二、本地运行博客"></a>二、本地运行博客</h1><h2 id="2-1-初始化Hexo项目"><a href="#2-1-初始化Hexo项目" class="headerlink" title="2.1 初始化Hexo项目"></a>2.1 初始化Hexo项目</h2><ol><li>初始化 Hexo 项目安装相关依赖：在D:\Blog目录下执行如下命令</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line">npm i  <span class="comment"># i==install</span></span><br></pre></td></tr></table></figure><ol start="2"><li>等待2分钟成功后即完成。其中，blog&#x2F;目录有如下结构：<ul><li>node_modules：依赖包</li><li>scaffolds：生成文章的一些模板</li><li>source：用来存放你的文章</li><li>themes：主题</li><li>.npmignore：发布时忽略的文件（可忽略）</li><li>_config.landscape.yml：主题的配置文件</li><li>config.yml：博客的配置文件</li><li>package.json：项目名称、描述、版本、运行和开发等信</li></ul></li></ol><h2 id="2-2-本地运行博客"><a href="#2-2-本地运行博客" class="headerlink" title="2.2 本地运行博客"></a>2.2 本地运行博客</h2><ol><li>输入 <code>hexo cl &amp;&amp; hexo s</code>启动项目</li><li>打开浏览器，输入地址：<a href="http://localhost:4000/">http://localhost:4000/</a> ，能打开说明你的博客已经构建成功了</li></ol><p>至此，已经完成搭建hexo，但其只能在本地局域网访问，若要在互联网上访问，还需托管到github pages上</p><h1 id="三、托管到Github-Pages"><a href="#三、托管到Github-Pages" class="headerlink" title="三、托管到Github Pages"></a>三、托管到Github Pages</h1><h2 id="3-1-Github准备"><a href="#3-1-Github准备" class="headerlink" title="3.1 Github准备"></a>3.1 Github准备</h2><ol><li>去<a href="https://github.com/">Github官网</a>创建Github账号</li><li>登录后，点击右上角的+按钮，选择New repository，创建一个&lt;你的用户名&gt;.github.io的仓库</li><li>注意，仓库名字的格式必须为：&lt;你的用户名&gt;.github.io (注意：前缀必须为用户名，此为预览博客需要，后期可修改仓库名)</li><li>可见性必须选择 Public 方便第一次部署检查问题，点击 Creat repository 进行创建即可</li></ol><h2 id="3-2-部署到Github"><a href="#3-2-部署到Github" class="headerlink" title="3.2 部署到Github"></a>3.2 部署到Github</h2><ol><li>安装 hexo-deployer-git</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><ol start="2"><li>修改 _config.yml 文件末尾</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:&lt;你的用户名&gt;/&lt;你的用户名&gt;.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure><ol start="3"><li>修改好配置后，运行如下命令，将代码部署到 GitHub。如果出现Deploy done，则说明部署成功了。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># VSCODE终端</span></span><br><span class="line">hexo cl; hexo g; hexo d</span><br></pre></td></tr></table></figure><pre><code>- hexo clean：删除之前生成的文件，可以用hexo cl缩写。- hexo generate：生成静态文章，可以用hexo g缩写- hexo deploy：部署文章，可以用hexo d缩写</code></pre><ol start="4"><li>稍等两分钟，打开浏览器访问：https:&#x2F;&#x2F;&lt;你的用户名&gt;.github.io ，这时候我们就可以看到博客内容了</li></ol><h2 id="3-3-自定义域名"><a href="#3-3-自定义域名" class="headerlink" title="3.3 自定义域名"></a>3.3 自定义域名</h2><ol><li>新建source&#x2F;CNAME文件，内容为你的自定义域名，如blog.dreamyai.fun</li><li>在你购买域名的云服务商那里，新增一条 <code>CNAME记录</code>：将 blog.dreamyai.fun 指向 &lt;你的用户名&gt;.github.io</li><li>等待几分钟生效后，即可通过访问你自己的域名来访问博客</li></ol><h1 id="四、写博客"><a href="#四、写博客" class="headerlink" title="四、写博客"></a>四、写博客</h1><p>用下面命令新建博文，然后用文本编辑器去编辑_posts&#x2F;新博文.md里的内容即可，注意要使用Markdown格式书写。详细使用方法可以查阅 <a href="https://hexo.io/zh-cn/docs/writing">https://hexo.io/zh-cn/docs/writing</a></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此命令会生成文件 source/_posts/新博文标题.md，之后手动打开文件按md格式写文章即可</span></span><br><span class="line">hexo new 新博文标题</span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地预览</span></span><br><span class="line">hexo cl; hexo s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送到线上</span></span><br><span class="line">hexo cl; hexo g; hexo d</span><br></pre></td></tr></table></figure><h1 id="五、云存储和恢复"><a href="#五、云存储和恢复" class="headerlink" title="五、云存储和恢复"></a>五、云存储和恢复</h1><p>上述部署推送到&lt;用户名&gt;.github.io仓库的只是 hexo generate 产生的静态网站内容。但我们的整个blog&#x2F;目录是保存在本地的，当换电脑或电脑出故障后，我们就无法继续维护我们的博客了。因此，需要把blog也推送到github的另一个仓库。因此：</p><ol><li>在github上新建一个blog私有仓库</li><li>在git bash中，cd到本地blog&#x2F;目录里面，执行如下命令</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;.DS_Store&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Thumbs.db&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;db.json&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;*.log&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;node_modules/&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;public/&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;.deploy*/&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;_multiconfig.yml&quot;</span> &gt;&gt; .gitignore</span><br><span class="line"></span><br><span class="line">git init</span><br><span class="line">git add *</span><br><span class="line">git commit -m <span class="string">&quot;first commit&quot;</span></span><br><span class="line">git branch -M main</span><br><span class="line">git remote add origin git@github.com:/&lt;你的github名称&gt;/&lt;仓库名&gt;.git</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><ol start="3"><li>每次更新了博客后，都可以同步到github</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add *</span><br><span class="line">git commit -m <span class="string">&quot;本次更新了什么&quot;</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><ol start="4"><li>如果更换电脑，从github上重新恢复工作</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --recursive git@github.com:/&lt;你的github名称&gt;/&lt;仓库名&gt;.git</span><br><span class="line">npm i</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://hexo.io/zh-cn/docs/">Hexo | 安装</a></li><li><a href="https://hexo.io/zh-cn/docs/setup">Hexo | 建站</a></li><li><a href="https://blog.cmliussss.com/p/HexoBlogNo1/">【Hexo博客系列】No.1 搭建Hexo博客，快速简洁高效，零成本搭建个人博客：Hexo + GitHub Pages + Cloudflare Pages 完整指南</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> github pages </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
